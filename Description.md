现在我们其他的文档和要求都不管！我们只专注服务器和客户端的通信协议指定
@docs/CommunicationProtocol_CS.md

为了你更方便的帮我规划通信协议具体内容细节
现在我将把我的通信需求详细给你描述一遍

首先大概描述一下
本项目是一个为博物馆开发的 智能体服务器
核心业务就是基于博物馆专有资料库建立的语义检索系统(SRS)，根据用户的提问以及具体客户端支持的函数调用，利用外部LLM服务做出综合性回应。


大致流程就是

步骤1(流程通信)
客户端(WEB)向服务端发起会话注册/登陆请求(支持账号密码或密钥进行身份验证)
发送注册请求时会将本客户端的基本属性
例如
Platform //客户端平台
RequireTTS //是否要求以语音回复
以及最重要的函数定义(FunctionCalling)
...
一并在注册请求中发送给服务器


步骤2(流程通信)
服务器收到注册请求后，首先进行用户身份验证(用户数据储存在服务器集成的SQLit数据库)
身份验证通过后会话管理模块负责为该客户端临时创建专有会话实例，并存储用户注册时提交的基本信息(包括FuncstionCalling)

步骤3(服务通信)
用户输入[文字、流式语音]
智能体客户端(WEB)采集并发送给智能体服务端
无论是文字还是流式语音，都是用的一个统一的报文结构通过字段控制报文实际有意义的字段
(服务通信阶段所有客户端发给服务端的请求报文都是统一一种结构！包括流式数据！但是语音数据是储存在单独的二进制帧！)
并且该报文还支持更新之前注册会话时提供的客户端属性信息
包括但不限于RequireTTS以及FunctionCalling


步骤4
服务器接收到消息[文字、流式语音]
>检查是否有客户端属性更新，例如RequireTTS&FunctionCalling，只要报文提供了就直接赋值给会话中的储存的客户端属性
>如果是文字那就一定是完整的信息，则直接进入下一个[步骤5]
>如果是流式语音则直接流式转发给外部的STT服务转为文字
此处的STT是流式输入，但是需要完整返回(关闭中间结果推送)
因为下一个环节是语义检索！必须要完整的语句！否则向量生成无意义。

步骤:5
将步骤2得到的文字信息，通过服务器集成的SRS客户端实例，调用外部的SRS服务
获取到语义相关的参考资料

步骤6
服务器收到相关资料后进行下一步最终提示词工程构建
1用户原始提问内容+2会话实例中储存的客户端函数定义+3SRS返回的相关资料
基于这三个数据进行最终提示词的整合，然后调用LLM API
这里相关资料和原始用户提问是整合为了对话内容，而函数定义是通过OpenAI兼容的LLM API参数填入的

步骤7
服务器接收LLM的流式文字响应
然后根据会话中的RequireTTS的值决定回复给客户端文字还是流式语音
RequireTTS=false就是不要求服务器回复语音
RequireTTS=true也就是要求服务器回复语音，那就要流式调用TTS服务
如果要调用TTS，那就是LLM的流式响应文字直接转发给流式TTS服务
并且TTS返回的音频数据也是流式的，为了减少流程等待延迟，TTS的输入和接收是同时进行的！要吗发是异步，要吗收是异步！
总之步骤7最终会产出
[流式文字数据]或[流式语音数据]

步骤8
将步骤7的结果包装为服务器响应客户端的专用报文
这里服务端回应客户端的业务报文也只有一种结构兼容所有消息类型
无论是流式文字还是流式语音都是这一种报文结构！

步骤9
WEB客户端接收到报文后进行数据提取
理论上允许一个报文同时包含
1.流式文字消息
2.流式语音消息
3.函数调用消息
客户端只负责分类提取后根据客户端具体实现执行后续
目前的web demo的实现是
@Demo 
以创建消息气泡的方式分别创建这三种消息气泡
对于流式数据报文中会有字段标记其是否为流式数据以及是第几个分片
因此同一个批多个流式数据只需要新增一个消息气泡
函数调用气泡理论上也会出现在LLM流式响应的第一个片段
因此也不会导致反复调用一个函数

到此我对我的项目的通信需求的描述应该就比较完善了
另外再补充一下

只有服务端和客户端的通信协议需要我们自己设计
对于服务器端调用外部的STT、TTS都是用阿里云官方当的Dashscope python sdk、调用SRS使用的是SRS的通信协议，都可以实现解耦

综上所述
请基于我的实际需求
帮我分析现有的通信协议存在的问题！
如果不合理的地方！请帮我升级优化调整！
@docs/CommunicationProtocol_CS.md 

不需要考虑任何兼容问题！本项目原本就是原型设计阶段！
新的设计直接取代旧的设计！严禁遗留旧版文件和代码！