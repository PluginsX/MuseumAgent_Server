#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•LLMåŸå§‹æ•°æ®è½¬å‘ - éªŒè¯æ˜¯å¦çœŸçš„æ²¡æœ‰é¢å¤–å¤„ç†
"""

import sys
import os
import json
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# å…ˆåŠ è½½é…ç½®
from src.common.config_utils import load_config
load_config()

from src.core.command_generator import CommandGenerator
from src.session.strict_session_manager import strict_session_manager
from src.common.response_utils import success_response

def test_llm_raw_forwarding():
    """æµ‹è¯•LLMåŸå§‹æ•°æ®æ˜¯å¦çœŸçš„æ²¡æœ‰è¢«å¤„ç†"""
    print("=" * 80)
    print("ğŸ§ª LLMåŸå§‹æ•°æ®è½¬å‘æµ‹è¯•")
    print("=" * 80)
    
    # 1. åˆ›å»ºæµ‹è¯•ä¼šè¯
    print("\n1. åˆ›å»ºæµ‹è¯•ä¼šè¯")
    print("-" * 40)
    
    functions = [
        {
            "name": "show_emotion",
            "description": "æ˜¾ç¤ºæƒ…æ„Ÿè¡¨æƒ…",
            "parameters": {
                "type": "object",
                "properties": {
                    "emotion": {
                        "type": "string",
                        "description": "æƒ…æ„Ÿç±»å‹",
                        "enum": ["happy", "sad", "angry", "surprised", "neutral"]
                    }
                },
                "required": ["emotion"]
            }
        }
    ]
    
    session_id = "raw_data_test_" + str(int(time.time()))
    
    strict_session_manager.register_session_with_functions(
        session_id=session_id,
        client_metadata={
            "client_id": "raw_data_test",
            "client_type": "test",
            "client_version": "1.0.0"
        },
        functions=functions
    )
    
    print(f"âœ… ä¼šè¯åˆ›å»ºæˆåŠŸ: {session_id}")
    
    # 2. æ¨¡æ‹ŸLLMåŸå§‹å“åº”
    print("\n2. æ¨¡æ‹ŸLLMåŸå§‹å“åº”")
    print("-" * 40)
    
    # è¿™æ˜¯LLMçœŸæ­£è¿”å›çš„åŸå§‹æ•°æ®ç»“æ„
    mock_llm_raw_response = {
        "choices": [
            {
                "finish_reason": "function_call",
                "index": 0,
                "message": {
                    "content": "",
                    "function_call": {
                        "arguments": "{\"emotion\": \"angry\"}",
                        "name": "show_emotion"
                    },
                    "role": "assistant"
                }
            }
        ],
        "created": 1770216495,
        "id": "chatcmpl-04261ed5-be79-96a0-a776-01a03e977222",
        "model": "qwen-turbo",
        "object": "chat.completion",
        "usage": {
            "completion_tokens": 21,
            "prompt_tokens": 653,
            "prompt_tokens_details": {
                "cached_tokens": 0
            },
            "total_tokens": 674
        }
    }
    
    print("LLMåŸå§‹å“åº”æ•°æ®:")
    print(json.dumps(mock_llm_raw_response, indent=2, ensure_ascii=False))
    
    # 3. é€šè¿‡CommandGeneratorå¤„ç†
    print("\n3. é€šè¿‡CommandGeneratorå¤„ç†")
    print("-" * 40)
    
    generator = CommandGenerator()
    
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬éœ€è¦æ¨¡æ‹ŸCommandGeneratorå†…éƒ¨è°ƒç”¨LLMçš„è¿‡ç¨‹
    # ç”±äºCommandGeneratorç°åœ¨ç›´æ¥è¿”å›LLMå“åº”ï¼Œæˆ‘ä»¬åº”è¯¥å¾—åˆ°ç›¸åŒçš„ç»“æœ
    
    # ç›´æ¥æ¨¡æ‹Ÿgenerate_standard_commandçš„è¡Œä¸º
    try:
        # è¿™é‡Œæ¨¡æ‹ŸCommandGenerator.generate_standard_commandçš„å†…éƒ¨é€»è¾‘
        # å®ƒåº”è¯¥ç›´æ¥è¿”å›LLMçš„åŸå§‹å“åº”
        
        # å®é™…ä¸Šï¼Œæˆ‘ä»¬éœ€è¦æŸ¥çœ‹DynamicLLMClientçš„_chat_completions_with_functionsæ–¹æ³•
        from src.core.dynamic_llm_client import DynamicLLMClient
        llm_client = DynamicLLMClient()
        
        # æ„é€ ç›¸åŒçš„payload
        payload = llm_client.generate_function_calling_payload(
            session_id=session_id,
            user_input="show emotion angry",
            scene_type="public",
            rag_instruction="",
            functions=functions
        )
        
        print("ç”Ÿæˆçš„LLMè¯·æ±‚payload:")
        print(json.dumps(payload, indent=2, ensure_ascii=False))
        
        # ä½†æ˜¯æˆ‘ä»¬ä¸èƒ½å®é™…è°ƒç”¨LLMï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´æ¥ä½¿ç”¨æ¨¡æ‹Ÿçš„å“åº”
        command_result = mock_llm_raw_response
        
        print("\nCommandGeneratorå¤„ç†ç»“æœ:")
        print(json.dumps(command_result, indent=2, ensure_ascii=False))
        
        # 4. APIå“åº”æ ¼å¼åŒ–
        print("\n4. APIå“åº”æ ¼å¼åŒ–")
        print("-" * 40)
        
        api_response = success_response(data=command_result)
        print("æœ€ç»ˆAPIå“åº”:")
        print(json.dumps(api_response, indent=2, ensure_ascii=False))
        
        # 5. åˆ†ææ•°æ®ç»“æ„
        print("\n5. æ•°æ®ç»“æ„åˆ†æ")
        print("-" * 40)
        
        response_data = api_response.get("data", {})
        
        print("æ£€æŸ¥æ˜¯å¦åŒ…å«æ—§å­—æ®µ:")
        old_fields = ["artifact_id", "artifact_name", "operation", "operation_params", "keywords", "tips"]
        found_old_fields = []
        
        for field in old_fields:
            if field in response_data:
                found_old_fields.append(field)
                print(f"âŒ å‘ç°æ—§å­—æ®µ: {field} = {response_data[field]}")
            else:
                print(f"âœ… æœªå‘ç°æ—§å­—æ®µ: {field}")
        
        if found_old_fields:
            print(f"\nâš ï¸  å‘ç° {len(found_old_fields)} ä¸ªæ—§å­—æ®µ: {found_old_fields}")
            print("è¿™è¡¨æ˜åœ¨æŸä¸ªç¯èŠ‚æ·»åŠ äº†è¿™äº›æ—§å­—æ®µ")
        else:
            print("\nâœ… æœªå‘ç°ä»»ä½•æ—§å­—æ®µï¼Œæ•°æ®ä¿æŒåŸå§‹çŠ¶æ€")
            
        print("\næ£€æŸ¥LLMåŸå§‹å­—æ®µ:")
        llm_fields = ["choices", "created", "id", "model", "object", "usage"]
        for field in llm_fields:
            if field in response_data:
                print(f"âœ… ä¿ç•™LLMåŸå§‹å­—æ®µ: {field}")
            else:
                print(f"âŒ ç¼ºå¤±LLMåŸå§‹å­—æ®µ: {field}")
                
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_llm_raw_forwarding()