#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®é™…ç½‘ç»œé€šä¿¡æµ‹è¯•
å±•ç¤ºçœŸå®çš„LLM APIè°ƒç”¨è¿‡ç¨‹å’ŒåŸå§‹æ•°æ®
"""

import requests
import json
import os
from datetime import datetime

def test_actual_llm_communication():
    """æµ‹è¯•å®é™…çš„LLMé€šä¿¡è¿‡ç¨‹"""
    
    print("=" * 80)
    print("å®é™…LLMé€šä¿¡æµ‹è¯•")
    print("=" * 80)
    print()
    
    # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®è·å–APIä¿¡æ¯
    base_url = os.getenv("LLM_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
    api_key = os.getenv("LLM_API_KEY", "sk-a7558f9302974d1891906107f6033939")
    model = os.getenv("LLM_MODEL", "qwen-turbo")
    
    if not api_key:
        print("âš ï¸  æœªé…ç½®LLM_API_KEYç¯å¢ƒå˜é‡ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®å±•ç¤º")
        show_mock_communication()
        return
    
    print(f"ğŸ“¡ è¿æ¥ä¿¡æ¯:")
    print(f"   Base URL: {base_url}")
    print(f"   Model: {model}")
    print(f"   API Key: {api_key[:8]}..." if api_key else "None")
    print()
    
    # æµ‹è¯•1: æ™®é€šå¯¹è¯
    print("ğŸ“‹ æµ‹è¯•1: æ™®é€šå¯¹è¯è¯·æ±‚")
    print("-" * 50)
    
    normal_payload = {
        "model": model,
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯è¾½å®çœåšç‰©é¦†æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·ä»¥å‹å¥½ã€ä¸“ä¸šçš„æ€åº¦å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
            },
            {
                "role": "user",
                "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è¾½å®çœåšç‰©é¦†ã€‚"
            }
        ],
        "temperature": 0.7,
        "max_tokens": 500
    }
    
    print("ğŸ“¤ å‘é€çš„åŸå§‹è¯·æ±‚:")
    print(json.dumps(normal_payload, ensure_ascii=False, indent=2))
    
    try:
        response = requests.post(
            f"{base_url}/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            json=normal_payload,
            timeout=30
        )
        
        print(f"\nğŸ“¥ HTTPçŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            raw_response = response.json()
            print("\nğŸ“¥ åŸå§‹å“åº”æ•°æ®:")
            print(json.dumps(raw_response, ensure_ascii=False, indent=2))
            
            # åˆ†æå“åº”
            message = raw_response.get("choices", [{}])[0].get("message", {})
            content = message.get("content", "")
            print(f"\nğŸ“ æå–çš„å¯¹è¯å†…å®¹: {content}")
            
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.text}")
            
    except Exception as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}")
    
    print("\n" + "=" * 80)
    
    # æµ‹è¯•2: Windowsæ¡Œå® å‡½æ•°è°ƒç”¨
    print("ğŸ“‹ æµ‹è¯•2: Windowsæ¡Œå® å‡½æ•°è°ƒç”¨è¯·æ±‚")
    print("-" * 50)
    
    desktop_pet_functions = [
        {
            "name": "move_to_position",
            "description": "ç§»åŠ¨æ¡Œå® åˆ°æŒ‡å®šå±å¹•ä½ç½®",
            "parameters": {
                "type": "object",
                "properties": {
                    "x": {
                        "type": "integer",
                        "description": "Xåæ ‡ä½ç½®(0-1920)"
                    },
                    "y": {
                        "type": "integer", 
                        "description": "Yåæ ‡ä½ç½®(0-1080)"
                    }
                },
                "required": ["x", "y"]
            }
        },
        {
            "name": "play_animation",
            "description": "æ’­æ”¾æ¡Œå® åŠ¨ç”»æ•ˆæœ",
            "parameters": {
                "type": "object",
                "properties": {
                    "animation_type": {
                        "type": "string",
                        "enum": ["happy", "sad", "angry", "surprised", "sleepy", "excited"],
                        "description": "åŠ¨ç”»ç±»å‹"
                    },
                    "duration": {
                        "type": "integer",
                        "description": "æŒç»­æ—¶é—´(ç§’)",
                        "minimum": 1,
                        "maximum": 30
                    }
                },
                "required": ["animation_type"]
            }
        },
        {
            "name": "speak_message",
            "description": "è®©æ¡Œå® è¯´è¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "text": {
                        "type": "string",
                        "description": "è¦è¯´çš„è¯"
                    },
                    "voice_type": {
                        "type": "string",
                        "enum": ["normal", "cute", "serious", "whisper"],
                        "description": "è¯­éŸ³ç±»å‹"
                    }
                },
                "required": ["text"]
            }
        },
        {
            "name": "change_mood",
            "description": "æ”¹å˜æ¡Œå® å¿ƒæƒ…çŠ¶æ€",
            "parameters": {
                "type": "object",
                "properties": {
                    "mood": {
                        "type": "string",
                        "enum": ["happy", "sad", "angry", "excited", "bored", "sleepy"],
                        "description": "å¿ƒæƒ…çŠ¶æ€"
                    }
                },
                "required": ["mood"]
            }
        },
        {
            "name": "perform_action",
            "description": "æ‰§è¡Œæ¡Œå® ç‰¹æ®ŠåŠ¨ä½œ",
            "parameters": {
                "type": "object",
                "properties": {
                    "action": {
                        "type": "string",
                        "enum": ["dance", "jump", "roll", "wave", "sit", "lie_down"],
                        "description": "åŠ¨ä½œç±»å‹"
                    },
                    "repeat_times": {
                        "type": "integer",
                        "description": "é‡å¤æ¬¡æ•°",
                        "minimum": 1,
                        "maximum": 10
                    }
                },
                "required": ["action"]
            }
        }
    ]
    
    function_payload = {
        "model": model,
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªå¯çˆ±çš„Windowsæ¡Œé¢å® ç‰©åŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚è°ƒç”¨ç›¸åº”çš„å‡½æ•°æ¥æ§åˆ¶æ¡Œå® çš„è¡Œä¸ºã€‚"
            },
            {
                "role": "user",
                "content": "è¯·è®©æ¡Œå® ç§»åŠ¨åˆ°å±å¹•å³ä¸Šè§’ï¼Œç„¶åå¼€å¿ƒåœ°è·³èˆ3æ¬¡ï¼Œæœ€åè¯´ä¸€å¥'ä¸»äººå›æ¥å•¦ï¼'"
            }
        ],
        "temperature": 0.1,
        "max_tokens": 500,
        "functions": desktop_pet_functions,
        "function_call": "auto"
    }
    
    print("ğŸ“¤ å‘é€çš„åŸå§‹è¯·æ±‚:")
    print(json.dumps(function_payload, ensure_ascii=False, indent=2))
    
    try:
        response2 = requests.post(
            f"{base_url}/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            json=function_payload,
            timeout=30
        )
        
        print(f"\nğŸ“¥ HTTPçŠ¶æ€ç : {response2.status_code}")
        
        if response2.status_code == 200:
            raw_response2 = response2.json()
            print("\nğŸ“¥ åŸå§‹å“åº”æ•°æ®:")
            print(json.dumps(raw_response2, ensure_ascii=False, indent=2))
            
            # åˆ†æå“åº”
            message2 = raw_response2.get("choices", [{}])[0].get("message", {})
            content2 = message2.get("content", "")
            function_call = message2.get("function_call")
            
            print(f"\nğŸ“ å¯¹è¯å†…å®¹: {content2}")
            if function_call:
                print(f"ğŸ”§ å‡½æ•°è°ƒç”¨: {function_call.get('name')}({function_call.get('arguments')})")
            else:
                print("ğŸ’¬ çº¯å¯¹è¯å“åº”")
                
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response2.text}")
            
    except Exception as e:
        print(f"âŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}")

def show_mock_communication():
    """å±•ç¤ºæ¨¡æ‹Ÿçš„é€šä¿¡æ•°æ®ï¼ˆå½“æ— çœŸå®APIæ—¶ï¼‰"""
    
    print("ğŸ“‹ æ¨¡æ‹Ÿé€šä¿¡æ•°æ®å±•ç¤º")
    print("-" * 50)
    
    # æ¨¡æ‹Ÿè¯·æ±‚1
    mock_request1 = {
        "model": "qwen-turbo",
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯è¾½å®çœåšç‰©é¦†æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·ä»¥å‹å¥½ã€ä¸“ä¸šçš„æ€åº¦å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
            },
            {
                "role": "user",
                "content": "è¾½å®çœåšç‰©é¦†æœ‰å“ªäº›ç‰¹è‰²å±•å“ï¼Ÿ"
            }
        ],
        "temperature": 0.7,
        "max_tokens": 800
    }
    
    print("ğŸ“¤ æ¨¡æ‹Ÿå‘é€çš„è¯·æ±‚:")
    print(json.dumps(mock_request1, ensure_ascii=False, indent=2))
    
    # æ¨¡æ‹Ÿå“åº”1
    mock_response1 = {
        "id": "chatcmpl-mock-001",
        "object": "chat.completion",
        "created": int(datetime.now().timestamp()),
        "model": "qwen-turbo",
        "choices": [
            {
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": "è¾½å®çœåšç‰©é¦†æ‹¥æœ‰ä¸°å¯Œçš„ç‰¹è‰²å±•å“ï¼Œä¸»è¦åŒ…æ‹¬ï¼š\n\n1. çº¢å±±æ–‡åŒ–ç‰å™¨ï¼šåŒ…æ‹¬è‘—åçš„ç‰çŒªé¾™ç­‰çè´µæ–‡ç‰©\n2. å•†å‘¨é’é“œå™¨ï¼šå±•ç¤ºäº†ä¸­å›½å¤ä»£é’é“œæ–‡åŒ–çš„ç²¾æ¹›å·¥è‰º\n3. å†ä»£é™¶ç“·ï¼šä»æ±‰å”åˆ°æ˜æ¸…å„æ—¶æœŸçš„ä»£è¡¨æ€§ç“·å™¨\n4. ä¹¦ç”»çå“ï¼šæ”¶è—äº†å¤§é‡å¤ä»£åå®¶ä¹¦ç”»ä½œå“\n5. æ»¡æ—æ–‡ç‰©ï¼šä½“ç°äº†æ»¡æ—å†å²æ–‡åŒ–ç‰¹è‰²"
                },
                "finish_reason": "stop"
            }
        ],
        "usage": {
            "prompt_tokens": 45,
            "completion_tokens": 128,
            "total_tokens": 173
        }
    }
    
    print("\nğŸ“¥ æ¨¡æ‹Ÿæ¥æ”¶çš„å“åº”:")
    print(json.dumps(mock_response1, ensure_ascii=False, indent=2))
    
    print("\n" + "=" * 80)
    
    # æ¨¡æ‹Ÿè¯·æ±‚2ï¼ˆWindowsæ¡Œå® å‡½æ•°è°ƒç”¨ï¼‰
    desktop_pet_mock_functions = [
        {
            "name": "move_to_position",
            "description": "ç§»åŠ¨æ¡Œå® åˆ°æŒ‡å®šå±å¹•ä½ç½®",
            "parameters": {
                "type": "object",
                "properties": {
                    "x": {"type": "integer", "description": "Xåæ ‡ä½ç½®(0-1920)"},
                    "y": {"type": "integer", "description": "Yåæ ‡ä½ç½®(0-1080)"}
                },
                "required": ["x", "y"]
            }
        },
        {
            "name": "play_animation",
            "description": "æ’­æ”¾æ¡Œå® åŠ¨ç”»æ•ˆæœ",
            "parameters": {
                "type": "object",
                "properties": {
                    "animation_type": {
                        "type": "string",
                        "enum": ["happy", "sad", "angry", "surprised", "sleepy", "excited"],
                        "description": "åŠ¨ç”»ç±»å‹"
                    },
                    "duration": {"type": "integer", "description": "æŒç»­æ—¶é—´(ç§’)", "minimum": 1, "maximum": 30}
                },
                "required": ["animation_type"]
            }
        },
        {
            "name": "speak_message",
            "description": "è®©æ¡Œå® è¯´è¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "text": {"type": "string", "description": "è¦è¯´çš„è¯"},
                    "voice_type": {
                        "type": "string",
                        "enum": ["normal", "cute", "serious", "whisper"],
                        "description": "è¯­éŸ³ç±»å‹"
                    }
                },
                "required": ["text"]
            }
        }
    ]
    
    mock_request2 = {
        "model": "qwen-turbo",
        "messages": [
            {
                "role": "system", 
                "content": "ä½ æ˜¯ä¸€ä¸ªå¯çˆ±çš„Windowsæ¡Œé¢å® ç‰©åŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚è°ƒç”¨ç›¸åº”çš„å‡½æ•°æ¥æ§åˆ¶æ¡Œå® çš„è¡Œä¸ºã€‚"
            },
            {
                "role": "user",
                "content": "è¯·è®©æ¡Œå® ç§»åŠ¨åˆ°å±å¹•ä¸­å¤®(960,540)ï¼Œæ’­æ”¾å¼€å¿ƒçš„åŠ¨ç”»5ç§’é’Ÿï¼Œç„¶åè¯´'æ¬¢è¿å›æ¥ï¼Œä¸»äººï¼'"
            }
        ],
        "temperature": 0.1,
        "max_tokens": 500,
        "functions": desktop_pet_mock_functions,
        "function_call": "auto"
    }
    
    print("ğŸ“¤ æ¨¡æ‹Ÿå‡½æ•°è°ƒç”¨è¯·æ±‚:")
    print(json.dumps(mock_request2, ensure_ascii=False, indent=2))
    
    # æ¨¡æ‹Ÿå“åº”2
    mock_response2 = {
        "id": "chatcmpl-mock-002",
        "object": "chat.completion", 
        "created": int(datetime.now().timestamp()),
        "model": "qwen-turbo",
        "choices": [
            {
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": "å¥½çš„ï¼æˆ‘æ¥æ§åˆ¶æ¡Œå® æ‰§è¡Œæ‚¨çš„æŒ‡ä»¤ã€‚é¦–å…ˆç§»åŠ¨åˆ°å±å¹•ä¸­å¤®ï¼Œç„¶åæ’­æ”¾å¼€å¿ƒåŠ¨ç”»ï¼Œæœ€åè¯´æ¬¢è¿è¯ã€‚",
                    "function_call": {
                        "name": "move_to_position",
                        "arguments": "{\n  \"x\": 960,\n  \"y\": 540\n}"
                    }
                },
                "finish_reason": "function_call"
            }
        ],
        "usage": {
            "prompt_tokens": 120,
            "completion_tokens": 75,
            "total_tokens": 195
        }
    }
    
    print("\nğŸ“¥ æ¨¡æ‹Ÿå‡½æ•°è°ƒç”¨å“åº”:")
    print(json.dumps(mock_response2, ensure_ascii=False, indent=2))
    
    print("\n" + "=" * 80)
    print("ğŸ“Š é€šä¿¡æµç¨‹è¯´æ˜")
    print("=" * 80)
    
    print("""
ğŸ¯ å®é™…é€šä¿¡æµç¨‹:

1. è¯·æ±‚æ„å»ºé˜¶æ®µ:
   â€¢ æ ¹æ®ä¼šè¯çŠ¶æ€ç¡®å®šæ˜¯å¦å¯ç”¨å‡½æ•°è°ƒç”¨
   â€¢ æ„é€ ç¬¦åˆOpenAIæ ‡å‡†çš„messagesæ•°ç»„
   â€¢ æ·»åŠ å¿…è¦çš„functionså’Œfunction_callå‚æ•°
   â€¢ è®¾ç½®æ¸©åº¦ã€tokené™åˆ¶ç­‰æ¨¡å‹å‚æ•°

2. ç½‘ç»œä¼ è¾“é˜¶æ®µ:
   â€¢ é€šè¿‡HTTPS POSTè¯·æ±‚å‘é€åˆ°LLM API
   â€¢ è¯·æ±‚å¤´åŒ…å«Authorizationå’ŒContent-Type
   â€¢ å®Œæ•´çš„JSONè´Ÿè½½ä½œä¸ºè¯·æ±‚ä½“

3. å“åº”å¤„ç†é˜¶æ®µ:
   â€¢ æ¥æ”¶æ ‡å‡†çš„Chat Completionå“åº”æ ¼å¼
   â€¢ è§£æchoicesæ•°ç»„ä¸­çš„messageå¯¹è±¡
   â€¢ æå–contentå­—æ®µçš„å¯¹è¯å†…å®¹
   â€¢ å¤„ç†function_callå­—æ®µçš„å‡½æ•°è°ƒç”¨ä¿¡æ¯

4. ç»“æœæ ‡å‡†åŒ–:
   â€¢ å°†åŸå§‹å“åº”è½¬æ¢ä¸ºç»Ÿä¸€çš„å†…éƒ¨æ ¼å¼
   â€¢ ä¿æŒcontentå¯¹è¯å†…å®¹çš„å®Œæ•´æ€§
   â€¢ æä¾›æ¸…æ™°çš„å‡½æ•°è°ƒç”¨æŒ‡ç¤º
   â€¢ è®°å½•å®Œæ•´çš„ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
    """)

if __name__ == "__main__":
    test_actual_llm_communication()