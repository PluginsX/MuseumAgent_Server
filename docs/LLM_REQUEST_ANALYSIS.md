# MuseumAgent æœåŠ¡å™¨ LLM API è¯·æ±‚æ„å»ºæµç¨‹åˆ†æ

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†åˆ†æ MuseumAgent æœåŠ¡å™¨å¦‚ä½•æ„å»ºæœ€ç»ˆå‘é€ç»™ LLM API çš„è¯·æ±‚ï¼ŒåŒ…æ‹¬æç¤ºè¯æ„å»ºã€å‚æ•°é…ç½®å’Œå®Œæ•´çš„è°ƒç”¨é“¾è·¯ã€‚

---

## ğŸ”„ å®Œæ•´è°ƒç”¨é“¾è·¯

```
å®¢æˆ·ç«¯è¯·æ±‚
    â†“
WebSocket åè®®å±‚ (agent_stream_router)
    â†“
CommandGenerator (åè°ƒå™¨)
    â†“
â”œâ”€ SemanticRetrievalProcessor (RAGæ£€ç´¢)
â”œâ”€ PromptBuilder (æç¤ºè¯æ„å»º)
â””â”€ DynamicLLMClient (LLMè°ƒç”¨)
    â†“
å¤–éƒ¨ LLM API (OpenAI å…¼å®¹)
```

---

## ğŸ“ è¯¦ç»†æµç¨‹åˆ†æ

### 1. å®¢æˆ·ç«¯è¯·æ±‚æ¥æ”¶

**ä½ç½®**: WebSocket åè®®å±‚

**æ¥æ”¶çš„å‚æ•°**ï¼š
```python
{
    "version": "1.0",
    "msg_type": "REQUEST",
    "session_id": "session_xxx",
    "payload": {
        "request_id": "req_xxx",
        "data_type": "TEXT" | "VOICE",
        "require_tts": true | false,      # âœ… å®¢æˆ·ç«¯é…ç½®
        "enable_srs": true | false,       # âœ… å®¢æˆ·ç«¯é…ç½®
        "content": {
            "text": "ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬"
        },
        "function_calling": [...]          # âœ… å®¢æˆ·ç«¯é…ç½®
    }
}
```

**å…³é”®é…ç½®å‚æ•°**ï¼š
- `require_tts`: æ˜¯å¦éœ€è¦ TTS è¯­éŸ³åˆæˆ
- `enable_srs`: æ˜¯å¦å¯ç”¨è¯­ä¹‰æ£€ç´¢ç³»ç»Ÿ (SRS)
- `function_calling`: å‡½æ•°è°ƒç”¨å®šä¹‰åˆ—è¡¨

---

### 2. CommandGenerator åè°ƒå¤„ç†

**ä½ç½®**: `src/core/command_generator.py`

**æ ¸å¿ƒæ–¹æ³•**: `generate_standard_command()`

#### æ­¥éª¤ 1: æ£€æŸ¥ EnableSRS é…ç½®

```python
# ä»ä¼šè¯ä¸­è·å– EnableSRS é…ç½®
session = strict_session_manager.get_session(session_id)
enable_srs = session.client_metadata.get("enable_srs", True)

print(f"[Coordinator] EnableSRS é…ç½®: {enable_srs}")
```

**è¯´æ˜**ï¼š
- å®¢æˆ·ç«¯å‘é€çš„ `enable_srs` å‚æ•°ä¼šä¿å­˜åˆ°ä¼šè¯çš„ `client_metadata` ä¸­
- æ¯æ¬¡è¯·æ±‚éƒ½ä¼šä»ä¼šè¯ä¸­è¯»å–æœ€æ–°çš„é…ç½®

#### æ­¥éª¤ 2: æ¡ä»¶æ‰§è¡Œ RAG æ£€ç´¢

```python
rag_context = None
if enable_srs:
    print(f"[Coordinator] æ‰§è¡Œ RAG æ£€ç´¢ï¼ˆEnableSRS=Trueï¼‰")
    rag_context = self._perform_rag_retrieval(user_input, session_id=session_id)
else:
    print(f"[Coordinator] è·³è¿‡ RAG æ£€ç´¢ï¼ˆEnableSRS=Falseï¼‰")
```

**RAG æ£€ç´¢ç»“æœç¤ºä¾‹**ï¼š
```python
{
    "artifacts": [
        {
            "id": "artifact_001",
            "name": "é’é“œé¼",
            "content": "å•†ä»£é’é“œå™¨ï¼Œç”¨äºç¥­ç¥€...",
            "score": 0.85
        },
        {
            "id": "artifact_002",
            "name": "ç‰ç’§",
            "content": "è¥¿å‘¨ç‰å™¨ï¼Œè±¡å¾æƒåŠ›...",
            "score": 0.78
        }
    ],
    "timestamp": "2026-02-19T23:45:00"
}
```

#### æ­¥éª¤ 3: è·å–å‡½æ•°å®šä¹‰

```python
# ä»ä¼šè¯ä¸­è·å– OpenAI æ ‡å‡†å‡½æ•°å®šä¹‰
functions = strict_session_manager.get_functions_for_session(session_id)

print(f"[Coordinator] è·å–åˆ°çš„å‡½æ•°æ•°é‡: {len(functions)}")
```

**å‡½æ•°å®šä¹‰ç¤ºä¾‹**ï¼š
```python
[
    {
        "name": "play_animation",
        "description": "æ’­æ”¾å® ç‰©åŠ¨ç”»",
        "parameters": {
            "type": "object",
            "properties": {
                "animation": {
                    "type": "string",
                    "enum": ["idle", "walk", "run", "jump"],
                    "description": "åŠ¨ç”»ç±»å‹"
                }
            },
            "required": ["animation"]
        }
    }
]
```

#### æ­¥éª¤ 4: æ„å»º RAG æŒ‡ä»¤

**ä½ç½®**: `src/core/modules/prompt_builder.py`

```python
def build_rag_instruction(self, rag_context: Dict[str, Any]) -> str:
    """æ„å»º RAG å¢å¼ºæŒ‡ä»¤"""
    artifacts = rag_context.get("artifacts", [])
    
    if not artifacts:
        return ""
    
    instruction = "ä»¥ä¸‹æ˜¯æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡ç‰©ä¿¡æ¯ï¼š\n\n"
    
    for i, artifact in enumerate(artifacts, 1):
        instruction += f"{i}. {artifact.get('name', 'æœªçŸ¥æ–‡ç‰©')}\n"
        instruction += f"   {artifact.get('content', 'æ— æè¿°')}\n"
        instruction += f"   ç›¸å…³åº¦: {artifact.get('score', 0):.2f}\n\n"
    
    instruction += "è¯·åŸºäºä»¥ä¸Šä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
    
    return instruction
```

**ç”Ÿæˆçš„ RAG æŒ‡ä»¤ç¤ºä¾‹**ï¼š
```
ä»¥ä¸‹æ˜¯æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡ç‰©ä¿¡æ¯ï¼š

1. é’é“œé¼
   å•†ä»£é’é“œå™¨ï¼Œç”¨äºç¥­ç¥€...
   ç›¸å…³åº¦: 0.85

2. ç‰ç’§
   è¥¿å‘¨ç‰å™¨ï¼Œè±¡å¾æƒåŠ›...
   ç›¸å…³åº¦: 0.78

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
```

---

### 3. DynamicLLMClient æ„å»ºè¯·æ±‚

**ä½ç½®**: `src/core/dynamic_llm_client.py`

**æ ¸å¿ƒæ–¹æ³•**: `generate_function_calling_payload()`

#### å®Œæ•´çš„è¯·æ±‚æ„å»ºé€»è¾‘

```python
def generate_function_calling_payload(
    self, 
    session_id: str, 
    user_input: str, 
    scene_type: str = "public", 
    rag_instruction: str = "", 
    functions: List[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """ç”Ÿæˆ OpenAI æ ‡å‡†å‡½æ•°è°ƒç”¨æ ¼å¼çš„è¯·æ±‚"""
    
    # 1. æ„å»ºç³»ç»Ÿæ¶ˆæ¯
    system_message = (
        "ä½ æ˜¯æ™ºèƒ½åŠ©æ‰‹ã€‚å¿…é¡»éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š\n"
        "1. æ¯æ¬¡å“åº”éƒ½å¿…é¡»åŒ…å«è‡ªç„¶è¯­è¨€å¯¹è¯å†…å®¹ï¼›\n"
        "2. åœ¨è°ƒç”¨å‡½æ•°æ—¶ï¼Œè¦å…ˆè§£é‡Šå°†è¦åšä»€ä¹ˆï¼›\n"
        "3. ç”¨å‹å¥½è‡ªç„¶çš„è¯­è¨€ä¸ç”¨æˆ·äº¤æµã€‚"
    )
    
    # 2. æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼ˆåŒ…å«åœºæ™¯å’Œ RAG ä¿¡æ¯ï¼‰
    user_message = f"åœºæ™¯ï¼š{scene_type}\n"
    
    if rag_instruction:
        user_message += f"{rag_instruction}\n"
    
    user_message += f"ç”¨æˆ·è¾“å…¥ï¼š{user_input}"
    
    # 3. æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": user_message}
    ]
    
    # 4. æ„å»ºåŸºç¡€ payload
    payload = {
        "model": self.model,  # ä»é…ç½®è¯»å–ï¼Œå¦‚ "qwen-turbo"
        "messages": messages,
        "temperature": self.parameters.get("temperature", 0.1),
        "max_tokens": self.parameters.get("max_tokens", 1024),
        "top_p": self.parameters.get("top_p", 0.1),
    }
    
    # 5. æ·»åŠ å‡½æ•°å®šä¹‰ï¼ˆå¦‚æœæœ‰ï¼‰
    if functions and len(functions) > 0:
        payload["functions"] = functions
        payload["function_call"] = "auto"
        print(f"[LLM] å·²æ·»åŠ  {len(functions)} ä¸ªå‡½æ•°å®šä¹‰")
    else:
        print("[LLM] æœªæä¾›å‡½æ•°å®šä¹‰ï¼Œä½¿ç”¨æ™®é€šå¯¹è¯æ¨¡å¼")
        messages[0]["content"] = (
            f"{system_message}\n\n"
            "å½“å‰å¤„äºæ™®é€šå¯¹è¯æ¨¡å¼ï¼Œè¯·ä»¥å‹å¥½ã€ä¸“ä¸šçš„æ€åº¦å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
        )
    
    return payload
```

---

### 4. æœ€ç»ˆå‘é€çš„ LLM API è¯·æ±‚

#### åœºæ™¯ A: å¯ç”¨ SRS + æœ‰å‡½æ•°å®šä¹‰

**å®Œæ•´è¯·æ±‚ç¤ºä¾‹**ï¼š
```json
{
  "model": "qwen-turbo",
  "messages": [
    {
      "role": "system",
      "content": "ä½ æ˜¯æ™ºèƒ½åŠ©æ‰‹ã€‚å¿…é¡»éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š\n1. æ¯æ¬¡å“åº”éƒ½å¿…é¡»åŒ…å«è‡ªç„¶è¯­è¨€å¯¹è¯å†…å®¹ï¼›\n2. åœ¨è°ƒç”¨å‡½æ•°æ—¶ï¼Œè¦å…ˆè§£é‡Šå°†è¦åšä»€ä¹ˆï¼›\n3. ç”¨å‹å¥½è‡ªç„¶çš„è¯­è¨€ä¸ç”¨æˆ·äº¤æµã€‚"
    },
    {
      "role": "user",
      "content": "åœºæ™¯ï¼špublic\nä»¥ä¸‹æ˜¯æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡ç‰©ä¿¡æ¯ï¼š\n\n1. é’é“œé¼\n   å•†ä»£é’é“œå™¨ï¼Œç”¨äºç¥­ç¥€...\n   ç›¸å…³åº¦: 0.85\n\n2. ç‰ç’§\n   è¥¿å‘¨ç‰å™¨ï¼Œè±¡å¾æƒåŠ›...\n   ç›¸å…³åº¦: 0.78\n\nè¯·åŸºäºä»¥ä¸Šä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\nç”¨æˆ·è¾“å…¥ï¼šä»‹ç»ä¸€ä¸‹é’é“œé¼"
    }
  ],
  "temperature": 0.1,
  "max_tokens": 1024,
  "top_p": 0.1,
  "functions": [
    {
      "name": "play_animation",
      "description": "æ’­æ”¾å® ç‰©åŠ¨ç”»",
      "parameters": {
        "type": "object",
        "properties": {
          "animation": {
            "type": "string",
            "enum": ["idle", "walk", "run", "jump"],
            "description": "åŠ¨ç”»ç±»å‹"
          }
        },
        "required": ["animation"]
      }
    }
  ],
  "function_call": "auto"
}
```

#### åœºæ™¯ B: ç¦ç”¨ SRS + æ— å‡½æ•°å®šä¹‰

**å®Œæ•´è¯·æ±‚ç¤ºä¾‹**ï¼š
```json
{
  "model": "qwen-turbo",
  "messages": [
    {
      "role": "system",
      "content": "ä½ æ˜¯æ™ºèƒ½åŠ©æ‰‹ã€‚å¿…é¡»éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š\n1. æ¯æ¬¡å“åº”éƒ½å¿…é¡»åŒ…å«è‡ªç„¶è¯­è¨€å¯¹è¯å†…å®¹ï¼›\n2. åœ¨è°ƒç”¨å‡½æ•°æ—¶ï¼Œè¦å…ˆè§£é‡Šå°†è¦åšä»€ä¹ˆï¼›\n3. ç”¨å‹å¥½è‡ªç„¶çš„è¯­è¨€ä¸ç”¨æˆ·äº¤æµã€‚\n\nå½“å‰å¤„äºæ™®é€šå¯¹è¯æ¨¡å¼ï¼Œè¯·ä»¥å‹å¥½ã€ä¸“ä¸šçš„æ€åº¦å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
    },
    {
      "role": "user",
      "content": "åœºæ™¯ï¼špublic\nç”¨æˆ·è¾“å…¥ï¼šä½ å¥½"
    }
  ],
  "temperature": 0.1,
  "max_tokens": 1024,
  "top_p": 0.1
}
```

#### åœºæ™¯ C: å¯ç”¨ SRS + æ— å‡½æ•°å®šä¹‰

**å®Œæ•´è¯·æ±‚ç¤ºä¾‹**ï¼š
```json
{
  "model": "qwen-turbo",
  "messages": [
    {
      "role": "system",
      "content": "ä½ æ˜¯æ™ºèƒ½åŠ©æ‰‹ã€‚å¿…é¡»éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š\n1. æ¯æ¬¡å“åº”éƒ½å¿…é¡»åŒ…å«è‡ªç„¶è¯­è¨€å¯¹è¯å†…å®¹ï¼›\n2. åœ¨è°ƒç”¨å‡½æ•°æ—¶ï¼Œè¦å…ˆè§£é‡Šå°†è¦åšä»€ä¹ˆï¼›\n3. ç”¨å‹å¥½è‡ªç„¶çš„è¯­è¨€ä¸ç”¨æˆ·äº¤æµã€‚\n\nå½“å‰å¤„äºæ™®é€šå¯¹è¯æ¨¡å¼ï¼Œè¯·ä»¥å‹å¥½ã€ä¸“ä¸šçš„æ€åº¦å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
    },
    {
      "role": "user",
      "content": "åœºæ™¯ï¼špublic\nä»¥ä¸‹æ˜¯æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡ç‰©ä¿¡æ¯ï¼š\n\n1. é’é“œé¼\n   å•†ä»£é’é“œå™¨ï¼Œç”¨äºç¥­ç¥€...\n   ç›¸å…³åº¦: 0.85\n\nè¯·åŸºäºä»¥ä¸Šä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\nç”¨æˆ·è¾“å…¥ï¼šä»‹ç»ä¸€ä¸‹é’é“œé¼"
    }
  ],
  "temperature": 0.1,
  "max_tokens": 1024,
  "top_p": 0.1
}
```

---

## ğŸ”§ é…ç½®å‚æ•°æ¥æº

### 1. LLM åŸºç¡€é…ç½®

**æ¥æº**: `config.json` æˆ–ç¯å¢ƒå˜é‡

```json
{
  "llm": {
    "base_url": "https://api.example.com/v1",
    "api_key": "sk-xxx",
    "model": "qwen-turbo",
    "parameters": {
      "temperature": 0.1,
      "max_tokens": 1024,
      "top_p": 0.1
    }
  }
}
```

### 2. å®¢æˆ·ç«¯åŠ¨æ€é…ç½®

**æ¥æº**: å®¢æˆ·ç«¯æ¯æ¬¡è¯·æ±‚æºå¸¦

```python
# ä»å®¢æˆ·ç«¯è¯·æ±‚ä¸­æå–
payload = message.get("payload", {})
require_tts = payload.get("require_tts", False)
enable_srs = payload.get("enable_srs", True)
function_calling = payload.get("function_calling", [])

# ä¿å­˜åˆ°ä¼šè¯
session.client_metadata["require_tts"] = require_tts
session.client_metadata["enable_srs"] = enable_srs
session.client_metadata["function_calling"] = function_calling
```

### 3. ä¼šè¯é…ç½®

**æ¥æº**: ä¼šè¯ç®¡ç†å™¨

```python
# ä»ä¼šè¯ä¸­è¯»å–é…ç½®
session = strict_session_manager.get_session(session_id)
enable_srs = session.client_metadata.get("enable_srs", True)
functions = session.client_metadata.get("function_calling", [])
```

---

## ğŸ“Š å‚æ•°ä¼˜å…ˆçº§

```
å®¢æˆ·ç«¯è¯·æ±‚å‚æ•° > ä¼šè¯é…ç½® > æœåŠ¡å™¨é»˜è®¤é…ç½®
```

**ç¤ºä¾‹**ï¼š
1. å®¢æˆ·ç«¯å‘é€ `enable_srs: false`
2. ä¿å­˜åˆ°ä¼šè¯: `session.client_metadata["enable_srs"] = false`
3. ä¸‹æ¬¡è¯·æ±‚ä»ä¼šè¯è¯»å–: `enable_srs = session.client_metadata.get("enable_srs", True)`
4. å¦‚æœä¼šè¯ä¸­æ²¡æœ‰ï¼Œä½¿ç”¨é»˜è®¤å€¼ `True`

---

## ğŸ¯ å…³é”®å†³ç­–ç‚¹

### å†³ç­– 1: æ˜¯å¦æ‰§è¡Œ RAG æ£€ç´¢

```python
if enable_srs:
    # æ‰§è¡Œ RAG æ£€ç´¢
    rag_context = self._perform_rag_retrieval(user_input)
    rag_instruction = self._build_rag_instruction(rag_context)
else:
    # è·³è¿‡ RAG æ£€ç´¢
    rag_instruction = ""
```

**å½±å“**ï¼š
- `enable_srs = true`: æç¤ºè¯åŒ…å«æ£€ç´¢åˆ°çš„æ–‡ç‰©ä¿¡æ¯
- `enable_srs = false`: æç¤ºè¯åªåŒ…å«ç”¨æˆ·è¾“å…¥

### å†³ç­– 2: æ˜¯å¦å¯ç”¨å‡½æ•°è°ƒç”¨

```python
if functions and len(functions) > 0:
    # å¯ç”¨å‡½æ•°è°ƒç”¨æ¨¡å¼
    payload["functions"] = functions
    payload["function_call"] = "auto"
else:
    # æ™®é€šå¯¹è¯æ¨¡å¼
    # ä¸æ·»åŠ  functions å­—æ®µ
```

**å½±å“**ï¼š
- æœ‰å‡½æ•°å®šä¹‰: LLM å¯ä»¥è°ƒç”¨å‡½æ•°
- æ— å‡½æ•°å®šä¹‰: LLM åªè¿”å›æ–‡æœ¬å“åº”

### å†³ç­– 3: æ˜¯å¦è°ƒç”¨ TTS

```python
# åœ¨å“åº”å¤„ç†é˜¶æ®µ
if require_tts:
    # è°ƒç”¨ TTS æœåŠ¡
    tts_audio = await tts_service.synthesize_text(llm_response)
else:
    # ä¸è°ƒç”¨ TTS
    tts_audio = None
```

**å½±å“**ï¼š
- `require_tts = true`: è¿”å›æ–‡æœ¬ + è¯­éŸ³
- `require_tts = false`: åªè¿”å›æ–‡æœ¬

---

## ğŸ” è°ƒè¯•æ—¥å¿—ç¤ºä¾‹

```
[Coordinator] å¼€å§‹OpenAIæ ‡å‡†å‡½æ•°è°ƒç”¨æµç¨‹
[Coordinator] EnableSRS é…ç½®: True
[Coordinator] æ­¥éª¤1: æ‰§è¡Œ RAG æ£€ç´¢ï¼ˆEnableSRS=Trueï¼‰
[RAG] æ£€ç´¢åˆ° 2 ä¸ªç›¸å…³æ–‡ç‰©
[Coordinator] æ­¥éª¤2: è·å–å‡½æ•°å®šä¹‰ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
[Coordinator] Session ID: session_xxx
[Coordinator] è·å–åˆ°çš„å‡½æ•°æ•°é‡: 1
[Coordinator] å‡½æ•°åˆ—è¡¨: ['play_animation']
[Coordinator] æ­¥éª¤3: æ„å»ºåŸºäºFunction Callingçš„æç¤ºè¯
[Coordinator] æ­¥éª¤4: ç”ŸæˆOpenAIæ ‡å‡†å‡½æ•°è°ƒç”¨è¯·æ±‚
[DEBUG] å‘é€åˆ°LLMçš„è¯·æ±‚è´Ÿè½½:
{
  "model": "qwen-turbo",
  "messages": [...],
  "temperature": 0.1,
  "max_tokens": 1024,
  "top_p": 0.1,
  "functions": [...],
  "function_call": "auto"
}
[Coordinator] æ­¥éª¤5: è°ƒç”¨LLMå¤„ç†å‡½æ•°è°ƒç”¨
[LLM] Sending function call request to LLM
[LLM] Successfully received LLM response
[DEBUG] LLMåŸå§‹å“åº”:
{
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": "å¥½çš„ï¼Œè®©æˆ‘ä¸ºä½ ä»‹ç»é’é“œé¼...",
        "function_call": {
          "name": "play_animation",
          "arguments": "{\"animation\": \"idle\"}"
        }
      }
    }
  ]
}
[Coordinator] æ­¥éª¤6: ç›´æ¥è½¬å‘LLMåŸå§‹å“åº”
[Coordinator] å¤„ç†å®Œæˆï¼Œç›´æ¥è½¬å‘LLMåŸå§‹å“åº”
```

---

## ğŸ“ æ€»ç»“

### æç¤ºè¯æ„å»ºæµç¨‹

```
1. ç³»ç»Ÿæ¶ˆæ¯ï¼ˆå›ºå®šï¼‰
   â†“
2. åœºæ™¯ä¿¡æ¯ï¼ˆscene_typeï¼‰
   â†“
3. RAG æ£€ç´¢ç»“æœï¼ˆå¦‚æœ enable_srs = trueï¼‰
   â†“
4. ç”¨æˆ·è¾“å…¥
   â†“
5. å‡½æ•°å®šä¹‰ï¼ˆå¦‚æœæœ‰ï¼‰
```

### API å‚æ•°æ„å»ºæµç¨‹

```
1. åŸºç¡€å‚æ•°ï¼ˆmodel, temperature, max_tokens, top_pï¼‰
   â† ä» config.json è¯»å–
   â†“
2. æ¶ˆæ¯åˆ—è¡¨ï¼ˆmessagesï¼‰
   â† ä»æç¤ºè¯æ„å»º
   â†“
3. å‡½æ•°å®šä¹‰ï¼ˆfunctions, function_callï¼‰
   â† ä»ä¼šè¯é…ç½®è¯»å–
   â†“
4. å‘é€åˆ° LLM API
```

### é…ç½®å‚æ•°æµè½¬

```
å®¢æˆ·ç«¯è®¾ç½®é¢æ¿
    â†“
WebSocket è¯·æ±‚ payload
    â†“
ä¼šè¯ client_metadata
    â†“
CommandGenerator è¯»å–
    â†“
DynamicLLMClient ä½¿ç”¨
    â†“
LLM API è¯·æ±‚
```

---

**æ‰€æœ‰é…ç½®å‚æ•°éƒ½èƒ½æ­£ç¡®ä¼ é€’å¹¶å½±å“æœ€ç»ˆçš„ LLM è¯·æ±‚ï¼** âœ…

