# å®Œæ•´æ¶æ„æµç¨‹ - é˜¶æ®µ 3-5ï¼šSRS æ£€ç´¢ã€æç¤ºè¯æ„å»ºä¸ LLM è°ƒç”¨

## ğŸ“‹ æµç¨‹æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°æµç¨‹çš„åä¸‰ä¸ªé˜¶æ®µï¼š
3. **æœåŠ¡å™¨æ ¹æ®è¦æ±‚é€‰æ‹©æ€§æŸ¥è¯¢ SRS è·å–ç›¸å…³èµ„æ–™**
4. **æœ€ç»ˆæç¤ºè¯æ„å»º**
5. **è°ƒç”¨ LLM API**

---

## ğŸ¯ é˜¶æ®µ 3ï¼šæœåŠ¡å™¨æ ¹æ®è¦æ±‚é€‰æ‹©æ€§æŸ¥è¯¢ SRS

### 3.1 å®¢æˆ·ç«¯å‘é€è¯·æ±‚

**æ–‡ä»¶**: `client/web/lib/core/SendManager.js`

```javascript
class SendManager {
    /**
     * å‘é€æ–‡æœ¬æ¶ˆæ¯ï¼ˆå®Œæ•´ç‰ˆï¼‰
     * @param {string} text - ç”¨æˆ·è¾“å…¥æ–‡æœ¬
     * @param {Object} options - å¯é€‰é…ç½®
     */
    sendText(text, options = {}) {
        const requestId = this.wsClient.generateId();
        
        const message = {
            version: '1.0',
            msg_type: 'REQUEST',
            session_id: this.sessionId,
            payload: {
                request_id: requestId,
                data_type: 'TEXT',
                stream_flag: false,
                stream_seq: 0,
                require_tts: options.requireTTS || false,
                content: { text }
            },
            timestamp: Date.now()
        };
        
        // âœ… æ„å»ºä¼šè¯æ›´æ–°ï¼ˆå¦‚æœæœ‰ï¼‰
        const updateSession = {};
        
        if (options.systemPrompt) {
            updateSession.system_prompt = options.systemPrompt;
        }
        
        if (options.sceneContext) {
            updateSession.scene_context = options.sceneContext;
        }
        
        if (options.enableSRS !== undefined) {
            updateSession.enable_srs = options.enableSRS;
        }
        
        if (options.functionCallingOp) {
            updateSession.function_calling_op = options.functionCallingOp;
            updateSession.function_calling = options.functionCalling || [];
        }
        
        // åªæœ‰åœ¨æœ‰æ›´æ–°æ—¶æ‰æ·»åŠ  update_session å­—æ®µ
        if (Object.keys(updateSession).length > 0) {
            message.payload.update_session = updateSession;
        }
        
        this.wsClient.send(message);
        
        return requestId;
    }
}
```

### 3.2 æœåŠ¡å™¨æ¥æ”¶è¯·æ±‚å¹¶æ›´æ–°ä¼šè¯

**æ–‡ä»¶**: `src/ws/agent_stream_router.py`

```python
async def handle_request_message(websocket, message: Dict[str, Any], session_id: str):
    """å¤„ç† REQUEST æ¶ˆæ¯"""
    try:
        payload = message.get("payload", {})
        request_id = payload.get("request_id")
        
        # âœ… æ£€æŸ¥æ˜¯å¦æœ‰ä¼šè¯æ›´æ–°
        update_session = payload.get("update_session", {})
        if update_session:
            logger.info(f"Updating session config for {session_id[:8]}")
            
            # æ›´æ–°ä¼šè¯é…ç½®
            success = strict_session_manager.update_session_attributes(
                session_id=session_id,
                system_prompt=update_session.get("system_prompt"),
                scene_context=update_session.get("scene_context"),
                require_tts=update_session.get("require_tts"),
                enable_srs=update_session.get("enable_srs"),
                function_calling_op=update_session.get("function_calling_op"),
                function_calling=update_session.get("function_calling")
            )
            
            if not success:
                logger.error(f"Failed to update session config for {session_id[:8]}")
        
        # éªŒè¯ä¼šè¯
        session = strict_session_manager.validate_session(session_id)
        if not session:
            await send_error_response(websocket, "Invalid session", request_id)
            return
        
        # è·å–ç”¨æˆ·è¾“å…¥
        content = payload.get("content", {})
        user_input = content.get("text", "")
        
        # âœ… ä»ä¼šè¯è·å– enable_srs é…ç½®
        enable_srs = session.client_metadata.get("enable_srs", True)
        
        # è°ƒç”¨å‘½ä»¤ç”Ÿæˆå™¨å¤„ç†è¯·æ±‚
        await command_generator.process_request(
            websocket=websocket,
            session_id=session_id,
            request_id=request_id,
            user_input=user_input,
            enable_srs=enable_srs  # âœ… ä¼ é€’ SRS å¼€å…³
        )
        
    except Exception as e:
        logger.error(f"Error handling request: {str(e)}")
        await send_error_response(websocket, str(e), request_id)
```

### 3.3 å‘½ä»¤ç”Ÿæˆå™¨å†³å®šæ˜¯å¦è°ƒç”¨ SRS

**æ–‡ä»¶**: `src/core/command_generator.py`

```python
class CommandGenerator:
    """å‘½ä»¤ç”Ÿæˆå™¨ï¼ˆå®Œæ•´ç‰ˆï¼‰"""
    
    async def process_request(
        self,
        websocket,
        session_id: str,
        request_id: str,
        user_input: str,
        enable_srs: bool = True
    ):
        """å¤„ç†ç”¨æˆ·è¯·æ±‚"""
        try:
            # è·å–ä¼šè¯
            session = strict_session_manager.get_session(session_id)
            if not session:
                raise ValueError("Session not found")
            
            # âœ… æ ¹æ® enable_srs å†³å®šæ˜¯å¦è°ƒç”¨ SRS
            rag_instruction = ""
            if enable_srs:
                logger.info(f"SRS enabled, querying relevant materials for: {user_input[:50]}")
                rag_instruction = await self._query_srs(user_input, session)
            else:
                logger.info(f"SRS disabled, skipping RAG retrieval")
            
            # è·å–å‡½æ•°å®šä¹‰
            functions = strict_session_manager.get_functions_for_session(session_id)
            
            # è·å–åœºæ™¯ç±»å‹ï¼ˆä»ä¼šè¯ä¸­è·å–ï¼‰
            scene_context = session.client_metadata.get("scene_context", {})
            scene_type = scene_context.get("current_scene", "public")
            
            # è°ƒç”¨ LLM
            await self._call_llm(
                websocket=websocket,
                session_id=session_id,
                request_id=request_id,
                user_input=user_input,
                scene_type=scene_type,
                rag_instruction=rag_instruction,
                functions=functions
            )
            
        except Exception as e:
            logger.error(f"Error processing request: {str(e)}")
            raise
    
    async def _query_srs(self, user_input: str, session: EnhancedClientSession) -> str:
        """æŸ¥è¯¢ SRS è·å–ç›¸å…³èµ„æ–™"""
        try:
            # è·å–åœºæ™¯å…³é”®è¯ï¼ˆç”¨äºä¼˜åŒ–æ£€ç´¢ï¼‰
            scene_context = session.client_metadata.get("scene_context", {})
            keywords = scene_context.get("keywords", [])
            
            # æ„å»ºæ£€ç´¢æŸ¥è¯¢ï¼ˆç»“åˆç”¨æˆ·è¾“å…¥å’Œåœºæ™¯å…³é”®è¯ï¼‰
            query = user_input
            if keywords:
                query = f"{user_input} {' '.join(keywords)}"
            
            # è°ƒç”¨ SRS API
            logger.info(f"Querying SRS with: {query[:100]}")
            srs_result = await self.srs_client.query(
                query=query,
                top_k=3,  # è¿”å›å‰ 3 ä¸ªæœ€ç›¸å…³çš„ç»“æœ
                threshold=0.7  # ç›¸å…³åº¦é˜ˆå€¼
            )
            
            # æ•´åˆæ£€ç´¢ç»“æœ
            if srs_result and srs_result.get("documents"):
                documents = srs_result["documents"]
                logger.info(f"SRS returned {len(documents)} relevant documents")
                
                # æ„å»º RAG æŒ‡ä»¤
                rag_instruction = "å‚è€ƒèµ„æ–™ï¼š\n"
                for idx, doc in enumerate(documents, 1):
                    content = doc.get("content", "")
                    score = doc.get("score", 0)
                    rag_instruction += f"{idx}. {content}\n"
                
                rag_instruction += "\nè¯·åŸºäºä»¥ä¸Šå‚è€ƒèµ„æ–™å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n"
                
                logger.info(f"RAG instruction generated: {len(rag_instruction)} chars")
                return rag_instruction
            else:
                logger.info("No relevant documents found in SRS")
                return ""
                
        except Exception as e:
            logger.error(f"Error querying SRS: {str(e)}")
            # SRS å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
            return ""
```

### 3.4 SRS å®¢æˆ·ç«¯å®ç°

**æ–‡ä»¶**: `src/services/srs_client.py`

```python
class SRSClient:
    """SRS æ£€ç´¢å¢å¼ºæœåŠ¡å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str, api_key: str = None):
        self.base_url = base_url
        self.api_key = api_key
        self.logger = get_enhanced_logger()
    
    async def query(
        self,
        query: str,
        top_k: int = 3,
        threshold: float = 0.7
    ) -> Dict[str, Any]:
        """æŸ¥è¯¢ç›¸å…³æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            threshold: ç›¸å…³åº¦é˜ˆå€¼
            
        Returns:
            æ£€ç´¢ç»“æœ
        """
        try:
            # æ„å»ºè¯·æ±‚
            request_data = {
                "query": query,
                "top_k": top_k,
                "threshold": threshold
            }
            
            headers = {}
            if self.api_key:
                headers["Authorization"] = f"Bearer {self.api_key}"
            
            # å‘é€è¯·æ±‚
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{self.base_url}/query",
                    json=request_data,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        self.logger.info(
                            "SRS query successful",
                            {
                                "query": query[:50],
                                "results": len(result.get("documents", []))
                            }
                        )
                        return result
                    else:
                        error_text = await response.text()
                        self.logger.error(
                            "SRS query failed",
                            {
                                "status": response.status,
                                "error": error_text
                            }
                        )
                        return {"documents": []}
                        
        except Exception as e:
            self.logger.error(f"SRS query exception: {str(e)}")
            return {"documents": []}
```

---

## ğŸ”¨ é˜¶æ®µ 4ï¼šæœ€ç»ˆæç¤ºè¯æ„å»º

### 4.1 ä»ä¼šè¯è·å–é…ç½®

**æ–‡ä»¶**: `src/core/dynamic_llm_client.py`

```python
class DynamicLLMClient:
    """åŠ¨æ€ LLM å®¢æˆ·ç«¯ï¼ˆå®Œæ•´ç‰ˆï¼‰"""
    
    def generate_function_calling_payload(
        self,
        session_id: str,
        user_input: str,
        scene_type: str = "public",
        rag_instruction: str = "",
        functions: List[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """ç”Ÿæˆ OpenAI æ ‡å‡†å‡½æ•°è°ƒç”¨æ ¼å¼çš„è¯·æ±‚"""
        
        # âœ… ä»ä¼šè¯ä¸­è·å–å®Œæ•´é…ç½®
        from ..session.strict_session_manager import strict_session_manager
        session = strict_session_manager.get_session(session_id)
        
        if not session:
            raise ValueError(f"Session {session_id} not found")
        
        # è·å–ç³»ç»Ÿæç¤ºè¯é…ç½®
        system_prompt_config = session.client_metadata.get("system_prompt", {})
        role_description = system_prompt_config.get(
            "role_description",
            "ä½ æ˜¯æ™ºèƒ½åŠ©æ‰‹ã€‚"
        )
        response_requirements = system_prompt_config.get(
            "response_requirements",
            "è¯·ç”¨å‹å¥½ã€ä¸“ä¸šçš„è¯­è¨€å›ç­”é—®é¢˜ã€‚"
        )
        
        # è·å–åœºæ™¯ä¸Šä¸‹æ–‡é…ç½®
        scene_context_config = session.client_metadata.get("scene_context", {})
        scene_description = scene_context_config.get(
            "scene_description",
            f"åœºæ™¯ï¼š{scene_type}"
        )
        scene_specific_prompt = scene_context_config.get(
            "scene_specific_prompt",
            ""
        )
        
        # âœ… æ„å»ºç³»ç»Ÿæ¶ˆæ¯
        system_message = f"{role_description}\n\n{response_requirements}"
        
        # å¦‚æœæœ‰å‡½æ•°å®šä¹‰ï¼Œæ·»åŠ å‡½æ•°è°ƒç”¨è§„åˆ™
        if functions and len(functions) > 0:
            system_message += "\n\nå¿…é¡»éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š\n"
            system_message += "1. æ¯æ¬¡å“åº”éƒ½å¿…é¡»åŒ…å«è‡ªç„¶è¯­è¨€å¯¹è¯å†…å®¹ï¼›\n"
            system_message += "2. åœ¨è°ƒç”¨å‡½æ•°æ—¶ï¼Œè¦å…ˆè§£é‡Šå°†è¦åšä»€ä¹ˆï¼›\n"
            system_message += "3. ç”¨å‹å¥½è‡ªç„¶çš„è¯­è¨€ä¸ç”¨æˆ·äº¤æµã€‚"
        
        # âœ… æ„å»ºç”¨æˆ·æ¶ˆæ¯
        user_message_parts = []
        
        # 1. åœºæ™¯æè¿°
        user_message_parts.append(scene_description)
        
        # 2. åœºæ™¯ç‰¹å®šæç¤º
        if scene_specific_prompt:
            user_message_parts.append(scene_specific_prompt)
        
        # 3. RAG æ£€ç´¢ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
        if rag_instruction:
            user_message_parts.append(rag_instruction)
        
        # 4. ç”¨æˆ·è¾“å…¥
        user_message_parts.append(f"ç”¨æˆ·è¾“å…¥ï¼š{user_input}")
        
        user_message = "\n\n".join(user_message_parts)
        
        # âœ… æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ]
        
        # è®°å½•æç¤ºè¯æ„å»ºä¿¡æ¯
        self.logger.info(
            "Prompt constructed",
            {
                "session_id": session_id[:8],
                "system_message_length": len(system_message),
                "user_message_length": len(user_message),
                "has_rag": bool(rag_instruction),
                "has_functions": bool(functions),
                "scene": scene_context_config.get("current_scene", "unknown")
            }
        )
        
        # âœ… æ„å»ºå®Œæ•´ payload
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": self.parameters.get("temperature", 0.1),
            "max_tokens": self.parameters.get("max_tokens", 1024),
            "top_p": self.parameters.get("top_p", 0.1),
        }
        
        # æ·»åŠ å‡½æ•°å®šä¹‰
        if functions and len(functions) > 0:
            payload["functions"] = functions
            payload["function_call"] = "auto"
        
        return payload
```

### 4.2 æç¤ºè¯æ„å»ºç¤ºä¾‹

**å®Œæ•´çš„æç¤ºè¯æ„å»ºç¤ºä¾‹**ï¼š

```python
# è¾“å…¥æ•°æ®
session_id = "session_abc123"
user_input = "ä»‹ç»ä¸€ä¸‹é’é“œé¼çš„å†å²"
rag_instruction = """å‚è€ƒèµ„æ–™ï¼š
1. é’é“œé¼æ˜¯ä¸­å›½å¤ä»£é‡è¦çš„ç¤¼å™¨ï¼Œå§‹äºå•†ä»£ï¼Œç››äºå‘¨ä»£ã€‚
2. è‘—åçš„å¸æ¯æˆŠé¼æ˜¯å•†ä»£æ™šæœŸçš„é’é“œå™¨ï¼Œé‡è¾¾832.84å…¬æ–¤ã€‚
"""

# ä»ä¼šè¯è·å–çš„é…ç½®
system_prompt = {
    "role_description": "ä½ æ˜¯åšç‰©é¦†æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“æ³¨äºæ–‡ç‰©çŸ¥è¯†è®²è§£å’Œäº’åŠ¨ä½“éªŒã€‚",
    "response_requirements": "è¯·ç”¨å‹å¥½ã€ä¸“ä¸šçš„è¯­è¨€å›ç­”é—®é¢˜ï¼Œæ³¨é‡çŸ¥è¯†æ€§å’Œè¶£å‘³æ€§çš„ç»“åˆã€‚"
}

scene_context = {
    "current_scene": "é“¸é€ å·¥è‰ºå±•ç¤ºåœºæ™¯",
    "scene_description": "å±•ç¤ºé’é“œå™¨çš„é“¸é€ å·¥è‰ºå’ŒæŠ€æœ¯æ¼”å˜",
    "scene_specific_prompt": "é‡ç‚¹ä»‹ç»é“¸é€ æŠ€æœ¯çš„å‘å±•å†ç¨‹å’Œå·¥è‰ºç‰¹ç‚¹"
}

# æ„å»ºåçš„æœ€ç»ˆæç¤ºè¯
final_prompt = {
    "messages": [
        {
            "role": "system",
            "content": """ä½ æ˜¯åšç‰©é¦†æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“æ³¨äºæ–‡ç‰©çŸ¥è¯†è®²è§£å’Œäº’åŠ¨ä½“éªŒã€‚

è¯·ç”¨å‹å¥½ã€ä¸“ä¸šçš„è¯­è¨€å›ç­”é—®é¢˜ï¼Œæ³¨é‡çŸ¥è¯†æ€§å’Œè¶£å‘³æ€§çš„ç»“åˆã€‚

å¿…é¡»éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1. æ¯æ¬¡å“åº”éƒ½å¿…é¡»åŒ…å«è‡ªç„¶è¯­è¨€å¯¹è¯å†…å®¹ï¼›
2. åœ¨è°ƒç”¨å‡½æ•°æ—¶ï¼Œè¦å…ˆè§£é‡Šå°†è¦åšä»€ä¹ˆï¼›
3. ç”¨å‹å¥½è‡ªç„¶çš„è¯­è¨€ä¸ç”¨æˆ·äº¤æµã€‚"""
        },
        {
            "role": "user",
            "content": """å±•ç¤ºé’é“œå™¨çš„é“¸é€ å·¥è‰ºå’ŒæŠ€æœ¯æ¼”å˜

é‡ç‚¹ä»‹ç»é“¸é€ æŠ€æœ¯çš„å‘å±•å†ç¨‹å’Œå·¥è‰ºç‰¹ç‚¹

å‚è€ƒèµ„æ–™ï¼š
1. é’é“œé¼æ˜¯ä¸­å›½å¤ä»£é‡è¦çš„ç¤¼å™¨ï¼Œå§‹äºå•†ä»£ï¼Œç››äºå‘¨ä»£ã€‚
2. è‘—åçš„å¸æ¯æˆŠé¼æ˜¯å•†ä»£æ™šæœŸçš„é’é“œå™¨ï¼Œé‡è¾¾832.84å…¬æ–¤ã€‚

ç”¨æˆ·è¾“å…¥ï¼šä»‹ç»ä¸€ä¸‹é’é“œé¼çš„å†å²"""
        }
    ]
}
```

---

## ğŸš€ é˜¶æ®µ 5ï¼šè°ƒç”¨ LLM API

### 5.1 å‘èµ· LLM API è°ƒç”¨

**æ–‡ä»¶**: `src/core/command_generator.py`

```python
async def _call_llm(
    self,
    websocket,
    session_id: str,
    request_id: str,
    user_input: str,
    scene_type: str,
    rag_instruction: str,
    functions: List[Dict[str, Any]]
):
    """è°ƒç”¨ LLM API"""
    try:
        # ç”Ÿæˆ LLM è¯·æ±‚ payload
        payload = self.llm_client.generate_function_calling_payload(
            session_id=session_id,
            user_input=user_input,
            scene_type=scene_type,
            rag_instruction=rag_instruction,
            functions=functions
        )
        
        # è·å–ä¼šè¯é…ç½®
        session = strict_session_manager.get_session(session_id)
        require_tts = session.client_metadata.get("require_tts", False)
        
        # è°ƒç”¨ LLMï¼ˆæµå¼å“åº”ï¼‰
        logger.info(f"Calling LLM API for request {request_id[:8]}")
        
        async for chunk in self.llm_client.stream_chat(payload):
            # å¤„ç†æµå¼å“åº”
            await self._handle_llm_chunk(
                websocket=websocket,
                session_id=session_id,
                request_id=request_id,
                chunk=chunk,
                require_tts=require_tts
            )
        
        logger.info(f"LLM API call completed for request {request_id[:8]}")
        
    except Exception as e:
        logger.error(f"Error calling LLM: {str(e)}")
        raise
```

### 5.2 å¤„ç† LLM å“åº”

```python
async def _handle_llm_chunk(
    self,
    websocket,
    session_id: str,
    request_id: str,
    chunk: Dict[str, Any],
    require_tts: bool
):
    """å¤„ç† LLM æµå¼å“åº”å—"""
    try:
        # æå–å†…å®¹
        content = chunk.get("content", "")
        function_call = chunk.get("function_call")
        
        # æ„å»ºå“åº”æ¶ˆæ¯
        response_message = {
            "version": "1.0",
            "msg_type": "RESPONSE",
            "session_id": session_id,
            "payload": {
                "request_id": request_id,
                "data_type": "TEXT",
                "content": {
                    "text": content
                },
                "is_final": chunk.get("is_final", False)
            },
            "timestamp": int(time.time() * 1000)
        }
        
        # å¦‚æœæœ‰å‡½æ•°è°ƒç”¨
        if function_call:
            response_message["payload"]["function_call"] = function_call
        
        # å‘é€å“åº”
        await websocket.send_json(response_message)
        
        # å¦‚æœéœ€è¦ TTS ä¸”æ˜¯æœ€ç»ˆå“åº”
        if require_tts and chunk.get("is_final") and content:
            await self._generate_tts(
                websocket=websocket,
                session_id=session_id,
                request_id=request_id,
                text=content
            )
        
    except Exception as e:
        logger.error(f"Error handling LLM chunk: {str(e)}")
```

---

## ğŸ“Š å®Œæ•´æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é˜¶æ®µ 3ï¼šSRS æ£€ç´¢                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç”¨æˆ·è¾“å…¥ï¼š"ä»‹ç»ä¸€ä¸‹é’é“œé¼çš„å†å²"
    â†“
SendManager.sendText(text, options)
    â†“
å‘é€ REQUEST æ¶ˆæ¯
    â†“
æœåŠ¡å™¨æ¥æ”¶æ¶ˆæ¯
    â†“
handle_request_message()
    â†“
æ£€æŸ¥ update_sessionï¼ˆå¦‚æœæœ‰ï¼‰
    â†“
æ›´æ–°ä¼šè¯é…ç½®
    â†“
éªŒè¯ä¼šè¯
    â†“
ä»ä¼šè¯è·å– enable_srs
    â†“
CommandGenerator.process_request()
    â†“
åˆ¤æ–­ï¼šenable_srs == true?
    â”œâ”€ Yes â†’ è°ƒç”¨ SRS API
    â”‚         â†“
    â”‚    SRSClient.query(user_input)
    â”‚         â†“
    â”‚    è¿”å›æ£€ç´¢ç»“æœ
    â”‚         â†“
    â”‚    æ•´åˆä¸º rag_instruction
    â”‚
    â””â”€ No â†’ rag_instruction = ""

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é˜¶æ®µ 4ï¼šæç¤ºè¯æ„å»º                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ä»ä¼šè¯è·å–é…ç½®
    â”œâ”€ system_prompt
    â”œâ”€ scene_context
    â”œâ”€ functions
    â””â”€ require_tts
    â†“
DynamicLLMClient.generate_function_calling_payload()
    â†“
æ„å»ºç³»ç»Ÿæ¶ˆæ¯
    = role_description + response_requirements + å‡½æ•°è°ƒç”¨è§„åˆ™
    â†“
æ„å»ºç”¨æˆ·æ¶ˆæ¯
    = scene_description + scene_specific_prompt + rag_instruction + user_input
    â†“
æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    = [system_message, user_message]
    â†“
æ„å»ºå®Œæ•´ payload
    = {model, messages, functions, temperature, ...}

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é˜¶æ®µ 5ï¼šè°ƒç”¨ LLM                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

DynamicLLMClient.stream_chat(payload)
    â†“
å‘é€è¯·æ±‚åˆ° LLM API
    â†“
æ¥æ”¶æµå¼å“åº”
    â†“
for each chunk:
    â†“
    æå– content å’Œ function_call
    â†“
    æ„å»º RESPONSE æ¶ˆæ¯
    â†“
    å‘é€ç»™å®¢æˆ·ç«¯
    â†“
    å¦‚æœ require_tts && is_final:
        â†“
        ç”Ÿæˆ TTS éŸ³é¢‘
        â†“
        å‘é€éŸ³é¢‘æ•°æ®
    â†“
LLM å“åº”å®Œæˆ
```

---

## âœ… å…³é”®è¦ç‚¹

### SRS æ£€ç´¢ï¼ˆé˜¶æ®µ 3ï¼‰
1. âœ… å®Œå…¨ç”±æœåŠ¡å™¨è´Ÿè´£
2. âœ… æ ¹æ® `enable_srs` å¼€å…³å†³å®šæ˜¯å¦è°ƒç”¨
3. âœ… æ£€ç´¢å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
4. âœ… ç»“åˆåœºæ™¯å…³é”®è¯ä¼˜åŒ–æ£€ç´¢

### æç¤ºè¯æ„å»ºï¼ˆé˜¶æ®µ 4ï¼‰
1. âœ… ä»ä¼šè¯å®æ—¶è·å–æ‰€æœ‰é…ç½®
2. âœ… ç³»ç»Ÿæ¶ˆæ¯ = è§’è‰²æè¿° + å“åº”è¦æ±‚ + å‡½æ•°è§„åˆ™
3. âœ… ç”¨æˆ·æ¶ˆæ¯ = åœºæ™¯æè¿° + åœºæ™¯æç¤º + RAG ç»“æœ + ç”¨æˆ·è¾“å…¥
4. âœ… ç»“æ„æ¸…æ™°ã€æ˜“äºè°ƒè¯•

### LLM è°ƒç”¨ï¼ˆé˜¶æ®µ 5ï¼‰
1. âœ… ä½¿ç”¨ OpenAI æ ‡å‡†æ ¼å¼
2. âœ… æ”¯æŒæµå¼å“åº”
3. âœ… æ”¯æŒå‡½æ•°è°ƒç”¨
4. âœ… æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ç”Ÿæˆ TTS

---

## ğŸ” æ•°æ®æµè½¬ç¤ºä¾‹

### è¾“å…¥æ•°æ®
```javascript
// å®¢æˆ·ç«¯å‘é€
{
    user_input: "ä»‹ç»ä¸€ä¸‹é’é“œé¼çš„å†å²",
    update_session: {
        scene_context: {
            current_scene: "é“¸é€ å·¥è‰ºå±•ç¤ºåœºæ™¯"
        }
    }
}
```

### ä¼šè¯é…ç½®
```python
# ä»ä¼šè¯è·å–
{
    "system_prompt": {
        "role_description": "ä½ æ˜¯åšç‰©é¦†æ™ºèƒ½åŠ©æ‰‹...",
        "response_requirements": "è¯·ç”¨å‹å¥½ã€ä¸“ä¸šçš„è¯­è¨€..."
    },
    "scene_context": {
        "current_scene": "é“¸é€ å·¥è‰ºå±•ç¤ºåœºæ™¯",
        "scene_description": "å±•ç¤ºé’é“œå™¨çš„é“¸é€ å·¥è‰º...",
        "scene_specific_prompt": "é‡ç‚¹ä»‹ç»é“¸é€ æŠ€æœ¯..."
    },
    "enable_srs": true,
    "require_tts": true,
    "functions": [...]
}
```

### SRS æ£€ç´¢ç»“æœ
```python
# æœåŠ¡å™¨è°ƒç”¨ SRS API
{
    "documents": [
        {
            "content": "é’é“œé¼æ˜¯ä¸­å›½å¤ä»£é‡è¦çš„ç¤¼å™¨...",
            "score": 0.95
        }
    ]
}

# æ•´åˆä¸º
rag_instruction = "å‚è€ƒèµ„æ–™ï¼š\n1. é’é“œé¼æ˜¯ä¸­å›½å¤ä»£é‡è¦çš„ç¤¼å™¨...\n"
```

### æœ€ç»ˆ LLM è¯·æ±‚
```python
{
    "model": "qwen-turbo",
    "messages": [
        {
            "role": "system",
            "content": "ä½ æ˜¯åšç‰©é¦†æ™ºèƒ½åŠ©æ‰‹...\n\nè¯·ç”¨å‹å¥½ã€ä¸“ä¸šçš„è¯­è¨€..."
        },
        {
            "role": "user",
            "content": "å±•ç¤ºé’é“œå™¨çš„é“¸é€ å·¥è‰º...\n\né‡ç‚¹ä»‹ç»é“¸é€ æŠ€æœ¯...\n\nå‚è€ƒèµ„æ–™ï¼š...\n\nç”¨æˆ·è¾“å…¥ï¼šä»‹ç»ä¸€ä¸‹é’é“œé¼çš„å†å²"
        }
    ],
    "functions": [...],
    "function_call": "auto"
}
```

---

**ä¸Šä¸€æ­¥**: [COMPLETE_ARCHITECTURE_FLOW_1.md](./COMPLETE_ARCHITECTURE_FLOW_1.md)  
**ä¸‹ä¸€æ­¥**: [COMPLETE_ARCHITECTURE_IMPL.md](./COMPLETE_ARCHITECTURE_IMPL.md)

