#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLMæ•°æ®äº¤äº’100%åŸå§‹æ•°æ®æ˜¾ç¤ºæ¼”ç¤º
å±•ç¤ºæœåŠ¡å™¨è°ƒç”¨LLMæ—¶å‘é€çš„å®Œæ•´åŸå§‹æ•°æ®å’Œæ¥æ”¶çš„å®Œæ•´åŸå§‹å“åº”
"""

import sys
import os
import json
sys.path.append('.')

from src.common.config_utils import load_config
load_config()

from src.core.dynamic_llm_client import DynamicLLMClient
from src.session.strict_session_manager import strict_session_manager

def demonstrate_raw_llm_interaction():
    """æ¼”ç¤ºLLMåŸå§‹æ•°æ®äº¤äº’è¿‡ç¨‹"""
    print("=== LLMæ•°æ®äº¤äº’100%åŸå§‹æ•°æ®æ˜¾ç¤º ===\n")
    
    # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
    llm_client = DynamicLLMClient()
    
    print("ğŸ”§ LLMå®¢æˆ·ç«¯é…ç½®ä¿¡æ¯:")
    print("-" * 50)
    print(f"Base URL: {llm_client.base_url}")
    print(f"Model: {llm_client.model}")
    print(f"Parameters: {json.dumps(llm_client.parameters, indent=2, ensure_ascii=False)}")
    print()
    
    # æµ‹è¯•ç”¨ä¾‹1: æ™®é€šå¯¹è¯æ¨¡å¼
    print("ğŸ“± æµ‹è¯•ç”¨ä¾‹1: æ™®é€šå¯¹è¯æ¨¡å¼")
    print("=" * 60)
    
    session_id_1 = "demo-session-001"
    user_input_1 = "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹è¾½å®çœåšç‰©é¦†"
    scene_type_1 = "public"
    
    # æ³¨å†Œç©ºå‡½æ•°å®šä¹‰çš„ä¼šè¯ï¼ˆæ™®é€šå¯¹è¯æ¨¡å¼ï¼‰
    strict_session_manager.register_session_with_functions(
        session_id=session_id_1,
        client_metadata={
            "client_id": "demo_client_1",
            "client_type": "demo",
            "client_version": "1.0.0"
        },
        functions=[]  # ç©ºå‡½æ•°åˆ—è¡¨ = æ™®é€šå¯¹è¯æ¨¡å¼
    )
    
    # ç”Ÿæˆå‡½æ•°è°ƒç”¨è´Ÿè½½
    print("ğŸ“¤ æ­¥éª¤1: ç”Ÿæˆå‘é€ç»™LLMçš„åŸå§‹è¯·æ±‚è´Ÿè½½")
    print("-" * 40)
    payload_1 = llm_client.generate_function_calling_payload(
        session_id=session_id_1,
        user_input=user_input_1,
        scene_type=scene_type_1,
        rag_instruction="",
        functions=[]
    )
    
    print("åŸå§‹è¯·æ±‚è´Ÿè½½ (JSONæ ¼å¼):")
    print(json.dumps(payload_1, indent=2, ensure_ascii=False))
    print()
    
    # æ˜¾ç¤ºHTTPè¯·æ±‚è¯¦æƒ…
    print("ğŸŒ HTTPè¯·æ±‚è¯¦æƒ…:")
    print("-" * 40)
    print(f"Method: POST")
    print(f"URL: {llm_client.base_url}/chat/completions")
    print(f"Headers: {{'Authorization': 'Bearer ***', 'Content-Type': 'application/json'}}")
    print(f"Timeout: {llm_client.timeout}ç§’")
    print()
    
    # æ¨¡æ‹ŸLLMå“åº”ï¼ˆå±•ç¤ºçœŸå®çš„å“åº”æ ¼å¼ï¼‰
    print("ğŸ“¥ æ­¥éª¤2: æ¨¡æ‹Ÿæ¥æ”¶çš„LLMåŸå§‹å“åº”")
    print("-" * 40)
    
    # æ™®é€šå¯¹è¯æ¨¡å¼çš„å…¸å‹å“åº”
    mock_response_1 = {
        "id": "chatcmpl-demo001",
        "object": "chat.completion",
        "created": 1707064800,
        "model": "qwen-turbo",
        "choices": [
            {
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": "æ‚¨å¥½ï¼è¾½å®çœåšç‰©é¦†æ˜¯ä½äºä¸­å›½è¾½å®çœæ²ˆé˜³å¸‚çš„ä¸€åº§å¤§å‹ç»¼åˆæ€§åšç‰©é¦†ã€‚è¯¥é¦†æˆç«‹äº1949å¹´ï¼Œæ˜¯å›½å®¶ä¸€çº§åšç‰©é¦†ï¼Œä¹Ÿæ˜¯è¾½å®çœæœ€å¤§çš„æ–‡ç‰©æ”¶è—ã€ä¿æŠ¤ã€ç ”ç©¶å’Œå±•ç¤ºæœºæ„ã€‚\n\nè¾½å®çœåšç‰©é¦†é¦†è—ä¸°å¯Œï¼Œæ¶µç›–äº†ä»å²å‰æ—¶æœŸåˆ°è¿‘ç°ä»£çš„å„ç±»æ–‡ç‰©ï¼ŒåŒ…æ‹¬é’é“œå™¨ã€é™¶ç“·ã€ä¹¦ç”»ã€ç‰å™¨ã€é‡‘é“¶å™¨ç­‰ã€‚å…¶ä¸­å°¤ä»¥è¾½ä»£æ–‡ç‰©æœ€ä¸ºè‘—åï¼Œå±•ç¤ºäº†å¥‘ä¸¹æ—å’Œè¾½ä»£æ–‡åŒ–çš„ç‹¬ç‰¹é­…åŠ›ã€‚\n\nåšç‰©é¦†å»ºç­‘å®ä¼Ÿï¼Œå±•è§ˆå†…å®¹ä¸°å¯Œå¤šæ ·ï¼Œæ—¢æœ‰å¸¸è®¾å±•è§ˆï¼Œä¹Ÿæœ‰ä¸´æ—¶ç‰¹å±•ã€‚é€šè¿‡ç°ä»£åŒ–çš„å±•ç¤ºæ‰‹æ®µå’Œè¯¦å®çš„è§£è¯´ï¼Œä¸ºè§‚ä¼—å‘ˆç°äº†è¾½å®åœ°åŒºæ·±åšçš„å†å²æ–‡åŒ–åº•è•´ã€‚\n\nå¦‚æœæ‚¨æœ‰æœºä¼šåˆ°æ²ˆé˜³æ—…æ¸¸ï¼Œè¾½å®çœåšç‰©é¦†ç»å¯¹æ˜¯å€¼å¾—ä¸€æ¸¸çš„æ–‡åŒ–åœ£åœ°ï¼"
                },
                "finish_reason": "stop"
            }
        ],
        "usage": {
            "prompt_tokens": 85,
            "completion_tokens": 215,
            "total_tokens": 300
        }
    }
    
    print("åŸå§‹å“åº”æ•°æ® (JSONæ ¼å¼):")
    print(json.dumps(mock_response_1, indent=2, ensure_ascii=False))
    print()
    
    # è§£æå“åº”
    print("ğŸ”„ æ­¥éª¤3: è§£æLLMå“åº”")
    print("-" * 40)
    parsed_result_1 = llm_client.parse_function_call_response(mock_response_1)
    print("è§£æåçš„æ ‡å‡†åŒ–æŒ‡ä»¤:")
    print(json.dumps(parsed_result_1, indent=2, ensure_ascii=False))
    print()
    
    # æµ‹è¯•ç”¨ä¾‹2: å‡½æ•°è°ƒç”¨æ¨¡å¼
    print("ğŸ“± æµ‹è¯•ç”¨ä¾‹2: å‡½æ•°è°ƒç”¨æ¨¡å¼")
    print("=" * 60)
    
    session_id_2 = "demo-session-002"
    user_input_2 = "è¯·ä»‹ç»èŸ é¾™ç›–ç½è¿™ä»¶æ–‡ç‰©"
    scene_type_2 = "study"
    
    # å®šä¹‰å‡½æ•°
    functions_2 = [
        {
            "name": "introduce_artifact",
            "description": "ä»‹ç»æ–‡ç‰©çš„è¯¦ç»†ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "artifact_name": {
                        "type": "string",
                        "description": "æ–‡ç‰©åç§°"
                    }
                },
                "required": ["artifact_name"]
            }
        }
    ]
    
    # æ³¨å†Œå¸¦å‡½æ•°å®šä¹‰çš„ä¼šè¯
    strict_session_manager.register_session_with_functions(
        session_id=session_id_2,
        client_metadata={
            "client_id": "demo_client_2", 
            "client_type": "demo",
            "client_version": "1.0.0"
        },
        functions=functions_2
    )
    
    # ç”Ÿæˆå‡½æ•°è°ƒç”¨è´Ÿè½½
    print("ğŸ“¤ æ­¥éª¤1: ç”Ÿæˆå‘é€ç»™LLMçš„åŸå§‹è¯·æ±‚è´Ÿè½½")
    print("-" * 40)
    payload_2 = llm_client.generate_function_calling_payload(
        session_id=session_id_2,
        user_input=user_input_2,
        scene_type=scene_type_2,
        rag_instruction="",
        functions=functions_2
    )
    
    print("åŸå§‹è¯·æ±‚è´Ÿè½½ (JSONæ ¼å¼):")
    print(json.dumps(payload_2, indent=2, ensure_ascii=False))
    print()
    
    # å‡½æ•°è°ƒç”¨æ¨¡å¼çš„å…¸å‹å“åº”
    print("ğŸ“¥ æ­¥éª¤2: æ¨¡æ‹Ÿæ¥æ”¶çš„LLMåŸå§‹å“åº”")
    print("-" * 40)
    
    mock_response_2 = {
        "id": "chatcmpl-demo002",
        "object": "chat.completion", 
        "created": 1707064900,
        "model": "qwen-turbo",
        "choices": [
            {
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": None,
                    "function_call": {
                        "name": "introduce_artifact",
                        "arguments": "{\n  \"artifact_name\": \"èŸ é¾™ç›–ç½\"\n}"
                    }
                },
                "finish_reason": "function_call"
            }
        ],
        "usage": {
            "prompt_tokens": 156,
            "completion_tokens": 28,
            "total_tokens": 184
        }
    }
    
    print("åŸå§‹å“åº”æ•°æ® (JSONæ ¼å¼):")
    print(json.dumps(mock_response_2, indent=2, ensure_ascii=False))
    print()
    
    # è§£æå‡½æ•°è°ƒç”¨å“åº”
    print("ğŸ”„ æ­¥éª¤3: è§£æå‡½æ•°è°ƒç”¨å“åº”")
    print("-" * 40)
    parsed_result_2 = llm_client.parse_function_call_response(mock_response_2)
    print("è§£æåçš„æ ‡å‡†åŒ–æŒ‡ä»¤:")
    print(json.dumps(parsed_result_2, indent=2, ensure_ascii=False))
    print()
    
    # å‚æ•°é…ç½®è¯¦æƒ…
    print("âš™ï¸ LLMå‚æ•°é…ç½®è¯¦æƒ…")
    print("=" * 60)
    print("å½“å‰ä½¿ç”¨çš„å‚æ•°é…ç½®:")
    print("-" * 30)
    config_params = llm_client.parameters
    param_details = {
        "temperature": f"{config_params.get('temperature', 0.1)} (æ§åˆ¶éšæœºæ€§ï¼Œ0-2)",
        "max_tokens": f"{config_params.get('max_tokens', 1024)} (æœ€å¤§è¾“å‡ºé•¿åº¦)",
        "top_p": f"{config_params.get('top_p', 0.1)} (æ ¸é‡‡æ ·ï¼Œ0-1)", 
        "stream": f"{config_params.get('stream', False)} (æ˜¯å¦æµå¼å“åº”)",
        "presence_penalty": f"{config_params.get('presence_penalty', 0)} (é‡å¤æƒ©ç½šï¼Œ-2åˆ°2)",
        "frequency_penalty": f"{config_params.get('frequency_penalty', 0)} (é¢‘ç‡æƒ©ç½šï¼Œ-2åˆ°2)"
    }
    
    for param, description in param_details.items():
        print(f"{param:20} : {description}")
    
    print()
    print("ğŸ“Š æ•°æ®ä¼ è¾“ç»Ÿè®¡:")
    print("-" * 30)
    print(f"æ™®é€šå¯¹è¯è¯·æ±‚å¤§å°: {len(json.dumps(payload_1))} å­—èŠ‚")
    print(f"æ™®é€šå¯¹è¯å“åº”å¤§å°: {len(json.dumps(mock_response_1))} å­—èŠ‚")
    print(f"å‡½æ•°è°ƒç”¨è¯·æ±‚å¤§å°: {len(json.dumps(payload_2))} å­—èŠ‚") 
    print(f"å‡½æ•°è°ƒç”¨å“åº”å¤§å°: {len(json.dumps(mock_response_2))} å­—èŠ‚")

def show_actual_api_call_example():
    """å±•ç¤ºå®é™…APIè°ƒç”¨ç¤ºä¾‹"""
    print("\n" + "=" * 80)
    print("ğŸ“¡ å®é™…APIè°ƒç”¨ç¤ºä¾‹")
    print("=" * 80)
    
    print("curlå‘½ä»¤ç¤ºä¾‹:")
    print("-" * 40)
    
    # æ™®é€šå¯¹è¯æ¨¡å¼çš„curlç¤ºä¾‹
    payload_example = {
        "model": "qwen-turbo",
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯è¾½å®çœåšç‰©é¦†æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚é€‰æ‹©åˆé€‚çš„å‡½æ•°å¹¶ç”Ÿæˆæ­£ç¡®çš„å‚æ•°ã€‚\n\nå½“å‰å¤„äºæ™®é€šå¯¹è¯æ¨¡å¼ï¼Œè¯·ä»¥å‹å¥½ã€ä¸“ä¸šçš„æ€åº¦å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
            },
            {
                "role": "user", 
                "content": "åœºæ™¯ï¼špublic\n\nç”¨æˆ·è¾“å…¥ï¼šä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹è¾½å®çœåšç‰©é¦†"
            }
        ],
        "temperature": 0.1,
        "max_tokens": 1024,
        "top_p": 0.1
    }
    
    print("æ™®é€šå¯¹è¯æ¨¡å¼:")
    print(f"curl -X POST '{llm_client.base_url}/chat/completions' \\")
    print(f"  -H 'Authorization: Bearer YOUR_API_KEY' \\")
    print(f"  -H 'Content-Type: application/json' \\")
    print(f"  -d '{json.dumps(payload_example, ensure_ascii=False)}'")
    print()
    
    # å‡½æ•°è°ƒç”¨æ¨¡å¼çš„curlç¤ºä¾‹
    function_payload_example = {
        "model": "qwen-turbo",
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯è¾½å®çœåšç‰©é¦†æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚é€‰æ‹©åˆé€‚çš„å‡½æ•°å¹¶ç”Ÿæˆæ­£ç¡®çš„å‚æ•°ã€‚"
            },
            {
                "role": "user",
                "content": "åœºæ™¯ï¼šstudy\n\nç”¨æˆ·è¾“å…¥ï¼šè¯·ä»‹ç»èŸ é¾™ç›–ç½è¿™ä»¶æ–‡ç‰©"
            }
        ],
        "functions": [
            {
                "name": "introduce_artifact",
                "description": "ä»‹ç»æ–‡ç‰©çš„è¯¦ç»†ä¿¡æ¯",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "artifact_name": {
                            "type": "string",
                            "description": "æ–‡ç‰©åç§°"
                        }
                    },
                    "required": ["artifact_name"]
                }
            }
        ],
        "function_call": "auto",
        "temperature": 0.1,
        "max_tokens": 1024,
        "top_p": 0.1
    }
    
    print("å‡½æ•°è°ƒç”¨æ¨¡å¼:")
    print(f"curl -X POST '{llm_client.base_url}/chat/completions' \\")
    print(f"  -H 'Authorization: Bearer YOUR_API_KEY' \\")
    print(f"  -H 'Content-Type: application/json' \\")
    print(f"  -d '{json.dumps(function_payload_example, ensure_ascii=False)}'")

if __name__ == "__main__":
    # å…¨å±€å˜é‡ç”¨äºåç»­ä½¿ç”¨
    llm_client = DynamicLLMClient()
    demonstrate_raw_llm_interaction()
    show_actual_api_call_example()
    print("\nâœ… LLMæ•°æ®äº¤äº’æ¼”ç¤ºå®Œæˆï¼")