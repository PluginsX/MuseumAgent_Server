#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç«¯åˆ°ç«¯æ•°æ®æµè½¬è¿½è¸ªæµ‹è¯•
æ¨¡æ‹Ÿå®Œæ•´çš„APIè°ƒç”¨æµç¨‹ï¼Œä»è¯·æ±‚åˆ°å“åº”çš„å…¨è¿‡ç¨‹
"""

import sys
import os
import json
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from src.common.config_utils import load_config
from src.core.dynamic_llm_client import DynamicLLMClient
from src.session.strict_session_manager import strict_session_manager
from src.core.command_generator import CommandGenerator
from src.common.response_utils import success_response

def end_to_end_trace_test():
    """ç«¯åˆ°ç«¯æ•°æ®æµè½¬è¿½è¸ªæµ‹è¯•"""
    print("=" * 100)
    print("ğŸ” ç«¯åˆ°ç«¯æ•°æ®æµè½¬è¿½è¸ªæµ‹è¯•")
    print("=" * 100)
    
    # åŠ è½½é…ç½®
    load_config()
    
    # 1. åˆå§‹åŒ–ç»„ä»¶
    print("\nğŸ”§ æ­¥éª¤1: åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶")
    print("-" * 50)
    llm_client = DynamicLLMClient()
    command_generator = CommandGenerator()
    
    # 2. åˆ›å»ºæµ‹è¯•ä¼šè¯
    print("\nğŸ“‹ æ­¥éª¤2: åˆ›å»ºæµ‹è¯•ä¼šè¯")
    print("-" * 50)
    session_id = "e2e-test-session-001"
    functions = [
        {
            "name": "move_to_position",
            "description": "ç§»åŠ¨åˆ°æŒ‡å®šåæ ‡ä½ç½®",
            "parameters": {
                "type": "object",
                "properties": {
                    "x": {"type": "number", "description": "Xåæ ‡"},
                    "y": {"type": "number", "description": "Yåæ ‡"}
                },
                "required": ["x", "y"]
            }
        }
    ]
    
    strict_session_manager.register_session_with_functions(
        session_id=session_id,
        client_metadata={
            "client_id": "e2e_test_client",
            "client_type": "test",
            "client_version": "1.0.0"
        },
        functions=functions
    )
    
    print(f"âœ… ä¼šè¯åˆ›å»ºæˆåŠŸ: {session_id}")
    print(f"âœ… æ³¨å†Œå‡½æ•°æ•°é‡: {len(functions)}")
    
    # 3. æ¨¡æ‹Ÿç”¨æˆ·è¯·æ±‚
    print("\nğŸ’¬ æ­¥éª¤3: æ¨¡æ‹Ÿç”¨æˆ·è¯·æ±‚")
    print("-" * 50)
    user_input = "ç§»åŠ¨åˆ°(0ï¼Œ0)"
    scene_type = "public"
    
    print(f"ç”¨æˆ·è¾“å…¥: {user_input}")
    print(f"åœºæ™¯ç±»å‹: {scene_type}")
    
    # 4. æ¨¡æ‹ŸLLMåŸå§‹å“åº”ï¼ˆå‡½æ•°è°ƒç”¨ï¼‰
    print("\nğŸ¤– æ­¥éª¤4: æ¨¡æ‹ŸLLMåŸå§‹å“åº”")
    print("-" * 50)
    mock_llm_response = {
        "id": "chatcmpl-e2e001",
        "object": "chat.completion",
        "created": 1707064900,
        "model": "qwen-turbo",
        "choices": [
            {
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": "æˆ‘å°†æŠŠæ¡Œé¢å® ç‰©ç§»åŠ¨åˆ°åæ ‡ (0, 0)ã€‚",
                    "function_call": {
                        "name": "move_to_position",
                        "arguments": "{\"x\": 0, \"y\": 0}"
                    }
                },
                "finish_reason": "function_call"
            }
        ],
        "usage": {
            "prompt_tokens": 85,
            "completion_tokens": 42,
            "total_tokens": 127
        }
    }
    
    print("LLMåŸå§‹å“åº”:")
    print(json.dumps(mock_llm_response, indent=2, ensure_ascii=False))
    
    # 5. ç›´æ¥è§£æLLMå“åº”
    print("\nğŸ”„ æ­¥éª¤5: ç›´æ¥è§£æLLMå“åº”")
    print("-" * 50)
    parsed_direct = llm_client.parse_function_call_response(mock_llm_response)
    print("ç›´æ¥è§£æç»“æœ:")
    print(json.dumps(parsed_direct, indent=2, ensure_ascii=False))
    
    # 6. é€šè¿‡CommandGeneratorå¤„ç†
    print("\nâš™ï¸ æ­¥éª¤6: é€šè¿‡CommandGeneratorå®Œæ•´æµç¨‹å¤„ç†")
    print("-" * 50)
    
    # æ¨¡æ‹ŸCommandGeneratorçš„å¤„ç†è¿‡ç¨‹ï¼ˆç»•è¿‡RAGä»¥é¿å…ä¾èµ–é—®é¢˜ï¼‰
    try:
        # æ‰‹åŠ¨æ‰§è¡ŒCommandGeneratorçš„å…³é”®æ­¥éª¤
        print("æ‰§è¡ŒRAGæ£€ç´¢...")
        # è·³è¿‡å®é™…RAGè°ƒç”¨ï¼Œç›´æ¥ä½¿ç”¨ç©ºä¸Šä¸‹æ–‡
        rag_context = {"total_found": 0, "timestamp": "2026-02-04T20:20:00"}
        
        print("è·å–å‡½æ•°å®šä¹‰...")
        session_functions = strict_session_manager.get_functions_for_session(session_id)
        print(f"ä¼šè¯å‡½æ•°: {len(session_functions)}ä¸ª")
        
        print("æ„å»ºæç¤ºè¯...")
        # ç®€åŒ–æç¤ºè¯æ„å»º
        rag_instruction = "ä¸Šä¸‹æ–‡ï¼šæ— ç›¸å…³æ–‡ç‰©ä¿¡æ¯"
        
        print("ç”Ÿæˆå‡½æ•°è°ƒç”¨è´Ÿè½½...")
        payload = llm_client.generate_function_calling_payload(
            session_id=session_id,
            user_input=user_input,
            scene_type=scene_type,
            rag_instruction=rag_instruction,
            functions=session_functions
        )
        
        print("è§£æLLMå“åº”...")
        # ä½¿ç”¨æˆ‘ä»¬æ¨¡æ‹Ÿçš„LLMå“åº”
        command_result = llm_client.parse_function_call_response(mock_llm_response)
        
        # æ·»åŠ å…ƒæ•°æ®
        command_result["timestamp"] = "2026-02-04T20:20:00"
        command_result["session_id"] = session_id
        command_result["processing_mode"] = "openai_function_calling"
        
        print("CommandGeneratorå¤„ç†ç»“æœ:")
        print(json.dumps(command_result, indent=2, ensure_ascii=False))
        
    except Exception as e:
        print(f"âŒ CommandGeneratorå¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 7. APIå“åº”æ ¼å¼åŒ–
    print("\nğŸŒ æ­¥éª¤7: APIå“åº”æ ¼å¼åŒ–")
    print("-" * 50)
    api_response = success_response(data=command_result)
    print("APIå“åº”æ•°æ®:")
    print(json.dumps(api_response, indent=2, ensure_ascii=False))
    
    # 8. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
    print("\nğŸ“‹ æ­¥éª¤8: æ•°æ®å®Œæ•´æ€§æ£€æŸ¥")
    print("-" * 50)
    response_data = api_response.get("data", {})
    
    print("å…³é”®å­—æ®µæ£€æŸ¥:")
    key_fields = ["command", "parameters", "type", "format", "response"]
    for field in key_fields:
        if field in response_data:
            value = response_data[field]
            if value is not None:
                print(f"âœ… {field}: {value}")
            else:
                print(f"âš ï¸  {field}: None")
        else:
            print(f"âŒ {field}: ä¸å­˜åœ¨")
    
    print("\nä¼ ç»Ÿå­—æ®µæ£€æŸ¥:")
    traditional_fields = ["artifact_id", "artifact_name", "operation", "operation_params"]
    for field in traditional_fields:
        if field in response_data:
            value = response_data[field]
            if value is None:
                print(f"âœ… {field}: None (é¢„æœŸ)")
            else:
                print(f"âš ï¸  {field}: {value} (æ„å¤–å€¼)")
        else:
            print(f"âœ… {field}: ä¸å­˜åœ¨ (é¢„æœŸ)")
    
    # 9. æ¨¡æ‹Ÿå®¢æˆ·ç«¯æ¥æ”¶
    print("\nğŸ“± æ­¥éª¤9: æ¨¡æ‹Ÿå®¢æˆ·ç«¯æ¥æ”¶å¤„ç†")
    print("-" * 50)
    
    # æ¨¡æ‹Ÿå®¢æˆ·ç«¯JavaScriptçš„å¤„ç†é€»è¾‘
    if api_response.get("code") == 200 and api_response.get("data"):
        client_command = api_response["data"]
        print("å®¢æˆ·ç«¯æ¥æ”¶åˆ°çš„åŸå§‹æ•°æ®:")
        print(json.dumps(client_command, indent=2, ensure_ascii=False))
        
        # æ¨¡æ‹Ÿå®¢æˆ·ç«¯æ˜¾ç¤ºé€»è¾‘
        print("\nå®¢æˆ·ç«¯æ˜¾ç¤ºé€»è¾‘æ¨¡æ‹Ÿ:")
        if "command" in client_command and client_command["command"]:
            print(f"ğŸ“ å‡½æ•°è°ƒç”¨: {client_command['command']}")
            if "parameters" in client_command and client_command["parameters"]:
                print(f"ğŸ”§ å‚æ•°: {client_command['parameters']}")
        else:
            print("âŒ æœªæ£€æµ‹åˆ°å‡½æ•°è°ƒç”¨ä¿¡æ¯")
            
        if "response" in client_command and client_command["response"]:
            print(f"ğŸ’¬ å¯¹è¯å†…å®¹: {client_command['response']}")
        else:
            print("âŒ æœªæ£€æµ‹åˆ°å¯¹è¯å†…å®¹")
    else:
        print("âŒ APIå“åº”æ ¼å¼é”™è¯¯")
    
    print("\n" + "=" * 100)
    print("ğŸ¯ ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆ")
    print("=" * 100)

if __name__ == "__main__":
    end_to_end_trace_test()